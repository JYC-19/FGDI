{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42e752b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self, num_classes=40, aux_logits=True, init_weights=True):\n",
    "        super(GoogLeNet,self).__init__()\n",
    "        self.aux_logits = aux_logits\n",
    "\n",
    "        self.conv1 = BasicConv1d(1, 64, kernel_size=7, stride=2, padding=3)     \n",
    "        self.maxpool1 = nn.MaxPool1d(3, stride=2, ceil_mode=True)               \n",
    "\n",
    "        self.conv2 = BasicConv1d(64, 64, kernel_size=1)\n",
    "        self.conv3 = BasicConv1d(64, 192, kernel_size=3, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool1d(3, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.maxpool3 = nn.MaxPool1d(3, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "        self.maxpool4 = nn.MaxPool1d(3, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "        if self.aux_logits:\n",
    "            self.aux1 = InceptionAux(512, num_classes)\n",
    "            self.aux2 = InceptionAux(528, num_classes)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.inception4a(x)\n",
    "        if self.training and self.aux_logits: \n",
    "            aux1 = self.aux1(x)\n",
    "\n",
    "        x = self.inception4b(x)\n",
    "        x = self.inception4c(x)\n",
    "        x = self.inception4d(x)\n",
    "        if self.training and self.aux_logits:\n",
    "            aux2 = self.aux2(x)\n",
    "\n",
    "        x = self.inception4e(x)\n",
    "        x = self.maxpool4(x)\n",
    "        x = self.inception5a(x)\n",
    "        x = self.inception5b(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        if self.training and self.aux_logits: \n",
    "            return x, aux2, aux1\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):\n",
    "        super(Inception,self).__init__()\n",
    "\n",
    "        self.branch1 = BasicConv1d(in_channels, ch1x1, kernel_size=1)\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv1d(in_channels, ch3x3red, kernel_size=1),\n",
    "            BasicConv1d(ch3x3red, ch3x3, kernel_size=3, padding=1)       \n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            BasicConv1d(in_channels, ch5x5red, kernel_size=1),\n",
    "            BasicConv1d(ch5x5red, ch5x5, kernel_size=5, padding=2)         \n",
    "        )\n",
    "\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=3, stride=1, padding=1),           \n",
    "            BasicConv1d(in_channels, pool_proj, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        branch3 = self.branch3(x)\n",
    "        branch4 = self.branch4(x)\n",
    "\n",
    "        outputs = [branch1, branch2, branch3, branch4]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "class InceptionAux(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(InceptionAux,self).__init__()\n",
    "        self.averagePool = nn.AvgPool1d(kernel_size=5, stride=3)\n",
    "        self.conv = BasicConv1d(in_channels, 128, kernel_size=1)       \n",
    "\n",
    "        self.fc1 = nn.Linear(3840, 1024)\n",
    "        self.fc2 = nn.Linear(1024,num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.averagePool(x)\n",
    "        x = self.conv(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = F.dropout(x, 0.5, training=self.training)\n",
    "        x = F.relu(self.fc1(x), inplace=True)\n",
    "        x = F.dropout(x, 0.5, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class BasicConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConv1d, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, **kwargs)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00936345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_matrix(conf_matrix, dev_list, save_path):\n",
    "    plt.figure(figsize=(20, 16))\n",
    "    plt.imshow(conf_matrix, cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "\n",
    "    thresh = conf_matrix.max() / 2.\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            plt.text(j, i, conf_matrix[i, j],\n",
    "                     ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if conf_matrix[i, j] > thresh else \"black\", fontsize=6)\n",
    "\n",
    "    tick_marks = np.arange(len(dev_list))\n",
    "    plt.xticks(tick_marks, dev_list)\n",
    "    plt.yticks(tick_marks, dev_list)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "012fc986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0 device.\n",
      "using 185997 images for training, 46497 images for validation.\n",
      "train loss:100%[**************************************************->]0.749\n",
      "[epoch 1] train_loss: 2.911 train_accuracy: 0.461 val_accuracy: 0.747  recall: 0.676  f1: 0.676\n",
      "train loss:100%[**************************************************->]1.052\n",
      "[epoch 2] train_loss: 1.220 train_accuracy: 0.782 val_accuracy: 0.832  recall: 0.764  f1: 0.765\n",
      "train loss:100%[**************************************************->]0.253\n",
      "[epoch 3] train_loss: 0.868 train_accuracy: 0.841 val_accuracy: 0.865  recall: 0.807  f1: 0.811\n",
      "train loss:100%[**************************************************->]0.323\n",
      "[epoch 4] train_loss: 0.692 train_accuracy: 0.874 val_accuracy: 0.884  recall: 0.824  f1: 0.828\n",
      "train loss:100%[**************************************************->]0.091\n",
      "[epoch 5] train_loss: 0.582 train_accuracy: 0.895 val_accuracy: 0.917  recall: 0.858  f1: 0.865\n",
      "train loss:100%[**************************************************->]0.224\n",
      "[epoch 6] train_loss: 0.502 train_accuracy: 0.910 val_accuracy: 0.936  recall: 0.873  f1: 0.877\n",
      "train loss:100%[**************************************************->]0.020\n",
      "[epoch 7] train_loss: 0.449 train_accuracy: 0.919 val_accuracy: 0.926  recall: 0.875  f1: 0.884\n",
      "train loss:100%[**************************************************->]0.512\n",
      "[epoch 8] train_loss: 0.412 train_accuracy: 0.925 val_accuracy: 0.937  recall: 0.884  f1: 0.894\n",
      "train loss:100%[**************************************************->]0.121\n",
      "[epoch 9] train_loss: 0.376 train_accuracy: 0.931 val_accuracy: 0.928  recall: 0.880  f1: 0.886\n",
      "train loss:100%[**************************************************->]0.148\n",
      "[epoch 10] train_loss: 0.347 train_accuracy: 0.935 val_accuracy: 0.946  recall: 0.895  f1: 0.903\n",
      "train loss:100%[**************************************************->]0.498\n",
      "[epoch 11] train_loss: 0.328 train_accuracy: 0.939 val_accuracy: 0.939  recall: 0.905  f1: 0.911\n",
      "train loss:100%[**************************************************->]0.108\n",
      "[epoch 12] train_loss: 0.309 train_accuracy: 0.942 val_accuracy: 0.943  recall: 0.910  f1: 0.919\n",
      "train loss:100%[**************************************************->]0.341\n",
      "[epoch 13] train_loss: 0.294 train_accuracy: 0.944 val_accuracy: 0.960  recall: 0.915  f1: 0.925\n",
      "train loss:100%[**************************************************->]1.326\n",
      "[epoch 14] train_loss: 0.279 train_accuracy: 0.946 val_accuracy: 0.950  recall: 0.921  f1: 0.930\n",
      "train loss:100%[**************************************************->]0.521\n",
      "[epoch 15] train_loss: 0.266 train_accuracy: 0.949 val_accuracy: 0.959  recall: 0.932  f1: 0.935\n",
      "train loss:100%[**************************************************->]0.718\n",
      "[epoch 16] train_loss: 0.256 train_accuracy: 0.952 val_accuracy: 0.949  recall: 0.927  f1: 0.933\n",
      "train loss:100%[**************************************************->]0.376\n",
      "[epoch 17] train_loss: 0.244 train_accuracy: 0.953 val_accuracy: 0.957  recall: 0.931  f1: 0.938\n",
      "train loss:100%[**************************************************->]0.076\n",
      "[epoch 18] train_loss: 0.234 train_accuracy: 0.955 val_accuracy: 0.956  recall: 0.932  f1: 0.940\n",
      "train loss:100%[**************************************************->]0.009\n",
      "[epoch 19] train_loss: 0.227 train_accuracy: 0.956 val_accuracy: 0.963  recall: 0.936  f1: 0.943\n",
      "train loss:100%[**************************************************->]0.075\n",
      "[epoch 20] train_loss: 0.219 train_accuracy: 0.957 val_accuracy: 0.957  recall: 0.935  f1: 0.942\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.categories = sorted(os.listdir(data_dir))\n",
    "        self.data = []\n",
    "        self.transform = transform\n",
    "        for category in self.categories:\n",
    "            category_dir = os.path.join(data_dir, category)\n",
    "            category_data = sorted(os.listdir(category_dir))\n",
    "            self.data.extend([(os.path.join(category_dir, file), self.categories.index(category)) for file in category_data])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_path, label = self.data[index]\n",
    "        data = np.load(file_path)\n",
    "        image = Image.fromarray(data.astype(np.uint8))\n",
    "        image = transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using {} device.\".format(device))\n",
    "\n",
    "transform = transforms.Compose([ transforms.Grayscale(num_output_channels = 1),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "train_dataset = CustomDataset(\"features/train_npy\",transform=transform)\n",
    "train_num = len(train_dataset)\n",
    "dev_list = train_dataset.categories\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size, shuffle=True,\n",
    "                                               num_workers=0)\n",
    "\n",
    "validate_dataset = CustomDataset(\"features/val_npy\",transform=transform)\n",
    "val_num = len(validate_dataset)\n",
    "validate_loader = torch.utils.data.DataLoader(validate_dataset,\n",
    "                                                  batch_size=batch_size, shuffle=False,\n",
    "                                                  num_workers=0)\n",
    "\n",
    "print(\"using {} images for training, {} images for validation.\".format(train_num, val_num))\n",
    "\n",
    "net = GoogLeNet(num_classes=27, aux_logits=True, init_weights=True)\n",
    "net.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "\n",
    "epochs = 20\n",
    "save_path = './GoogLeNet_parameters.pth'\n",
    "best_f1 = 0.0\n",
    "train_accurate_list = []\n",
    "val_accurate_list = []\n",
    "f1_list = []\n",
    "recall_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for step, data in enumerate(train_loader, start=0):\n",
    "        images, labels = data\n",
    "        images = images.reshape(images.shape[0], 1, 1500)\n",
    "        optimizer.zero_grad()\n",
    "        logits, aux_logits2, aux_logits1 = net(images.to(device))\n",
    "        predict_y = torch.max(logits, dim=1)[1]\n",
    "        train_acc += torch.eq(predict_y, labels.to(device)).sum().item()\n",
    "        loss0 = loss_function(logits, labels.to(device))\n",
    "        loss1 = loss_function(aux_logits1, labels.to(device))\n",
    "        loss2 = loss_function(aux_logits2, labels.to(device))\n",
    "        loss = loss0 + loss1 * 0.3 + loss2 * 0.3\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        rate = (step + 1) / len(train_loader)\n",
    "        a = \"*\" * int(rate * 50)\n",
    "        b = \".\" * int((1 - rate) * 50)\n",
    "        print(\"\\rtrain loss:{:^3.0f}%[{}->{}]{:.3f}\".format(int(rate * 100), a, b, loss), end=\"\")\n",
    "    print()\n",
    "    train_accurate = train_acc / train_num\n",
    "    train_accurate_list.append(train_accurate)\n",
    "    net.eval()\n",
    "    acc = 0.0\n",
    "    val = torch.tensor([])\n",
    "    pre = torch.tensor([])\n",
    "    with torch.no_grad():\n",
    "        for val_data in validate_loader:\n",
    "            val_images, val_labels = val_data\n",
    "            val_images = val_images.reshape(val_images.shape[0], 1, 1500)\n",
    "            outputs = net(val_images.to(device))\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            pre = torch.cat([pre.to(device), predict_y.to(device)])\n",
    "            val = torch.cat([val.to(device), val_labels.to(device)])\n",
    "            acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "    val_accurate = acc / val_num\n",
    "    val_accurate_list.append(val_accurate)\n",
    "    f1 = f1_score(val.cpu(), pre.cpu(), average='macro')\n",
    "    recall = recall_score(val.cpu(), pre.cpu(), average='macro')\n",
    "\n",
    "    f1_list.append(f1)\n",
    "    recall_list.append(recall)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_pre = pre\n",
    "        best_val = val\n",
    "        torch.save(net.state_dict(), save_path)\n",
    "        torch.save(best_pre, 'pre_val_label/best_pre_GoogLeNet.pt')\n",
    "        torch.save(best_val, 'pre_val_label/best_val_GoogLeNet.pt')\n",
    "    print('[epoch %d] train_loss: %.3f train_accuracy: %.3f val_accuracy: %.3f  recall: %.3f  f1: %.3f' %\n",
    "              (epoch + 1, running_loss / step, train_accurate, val_accurate, recall, f1))\n",
    "    with open(\"GoogLeNet_result_npy.txt\", 'a') as file:\n",
    "        file.write(\"[epoch \" + str(epoch + 1) + \"]\" + \"  \" + \"train_accuracy:\" + str(train_accurate) + \"  \" + \"val_accuracy:\" + str(val_accurate) + \"  \" + \"recall:\" + str(recall) + \"  \" + \"f1:\" + str(f1) + '\\n')\n",
    "print('Finished Training')\n",
    "iterations = range(1, len(train_accurate_list) + 1)\n",
    "with open(\"GoogLeNet_npy_plt_data.txt\", 'a') as file:\n",
    "    file.write(\"iterations:\" + str(iterations) +\n",
    "               \"train_accurate_list:\" + str(train_accurate_list) +\n",
    "               \"val_accurate_list:\" + str(val_accurate_list) +\n",
    "               \"f1_list:\" + str(f1_list) +\n",
    "               \"recall_list:\" + str(recall_list) +\n",
    "               \"dev_list:\" + str(dev_list) + '\\n')\n",
    "conf_matrix = confusion_matrix(best_val.cpu(),best_pre.cpu())\n",
    "plot_matrix(conf_matrix,dev_list,\"GoogLeNet_confusion_matrix_npy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288b4c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
