{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e77deb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=40, init_weights=False):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(1, 48, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2),\n",
    "            nn.Conv1d(48, 128, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2),\n",
    "            nn.Conv1d(128, 192, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(192, 192, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(192, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(5760, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2048, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4c0e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_matrix(conf_matrix, dev_list, save_path):\n",
    "    plt.figure(figsize=(20, 16))\n",
    "    plt.imshow(conf_matrix, cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "\n",
    "    thresh = conf_matrix.max() / 2.\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            plt.text(j, i, conf_matrix[i, j],\n",
    "                     ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if conf_matrix[i, j] > thresh else \"black\", fontsize=6)\n",
    "\n",
    "    tick_marks = np.arange(len(dev_list))\n",
    "    plt.xticks(tick_marks, dev_list)\n",
    "    plt.yticks(tick_marks, dev_list)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb02a9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0 device.\n",
      "using 185997 images for training, 46497 images for validation.\n",
      "train loss:100%[**************************************************->]0.513\n",
      "[epoch 1] train_loss: 1.137 train_accuracy: 0.655 val_accuracy: 0.826  recall: 0.754  f1: 0.751\n",
      "train loss:100%[**************************************************->]0.205\n",
      "[epoch 2] train_loss: 0.485 train_accuracy: 0.838 val_accuracy: 0.877  recall: 0.813  f1: 0.818\n",
      "train loss:100%[**************************************************->]0.038\n",
      "[epoch 3] train_loss: 0.357 train_accuracy: 0.876 val_accuracy: 0.893  recall: 0.843  f1: 0.851\n",
      "train loss:100%[**************************************************->]0.125\n",
      "[epoch 4] train_loss: 0.290 train_accuracy: 0.897 val_accuracy: 0.914  recall: 0.878  f1: 0.886\n",
      "train loss:100%[**************************************************->]0.612\n",
      "[epoch 5] train_loss: 0.251 train_accuracy: 0.909 val_accuracy: 0.916  recall: 0.885  f1: 0.894\n",
      "train loss:100%[**************************************************->]0.056\n",
      "[epoch 6] train_loss: 0.227 train_accuracy: 0.917 val_accuracy: 0.913  recall: 0.881  f1: 0.890\n",
      "train loss:100%[**************************************************->]0.081\n",
      "[epoch 7] train_loss: 0.207 train_accuracy: 0.923 val_accuracy: 0.927  recall: 0.896  f1: 0.906\n",
      "train loss:100%[**************************************************->]0.024\n",
      "[epoch 8] train_loss: 0.191 train_accuracy: 0.928 val_accuracy: 0.936  recall: 0.906  f1: 0.916\n",
      "train loss:100%[**************************************************->]0.126\n",
      "[epoch 9] train_loss: 0.180 train_accuracy: 0.932 val_accuracy: 0.924  recall: 0.898  f1: 0.908\n",
      "train loss:100%[**************************************************->]0.253\n",
      "[epoch 10] train_loss: 0.171 train_accuracy: 0.935 val_accuracy: 0.943  recall: 0.917  f1: 0.925\n",
      "train loss:100%[**************************************************->]0.339\n",
      "[epoch 11] train_loss: 0.163 train_accuracy: 0.938 val_accuracy: 0.935  recall: 0.915  f1: 0.921\n",
      "train loss:100%[**************************************************->]0.004\n",
      "[epoch 12] train_loss: 0.156 train_accuracy: 0.941 val_accuracy: 0.959  recall: 0.929  f1: 0.939\n",
      "train loss:100%[**************************************************->]0.127\n",
      "[epoch 13] train_loss: 0.148 train_accuracy: 0.943 val_accuracy: 0.941  recall: 0.919  f1: 0.927\n",
      "train loss:100%[**************************************************->]0.509\n",
      "[epoch 14] train_loss: 0.144 train_accuracy: 0.945 val_accuracy: 0.945  recall: 0.921  f1: 0.930\n",
      "train loss:100%[**************************************************->]0.004\n",
      "[epoch 15] train_loss: 0.139 train_accuracy: 0.947 val_accuracy: 0.958  recall: 0.933  f1: 0.941\n",
      "train loss:100%[**************************************************->]0.350\n",
      "[epoch 16] train_loss: 0.132 train_accuracy: 0.950 val_accuracy: 0.955  recall: 0.936  f1: 0.944\n",
      "train loss:100%[**************************************************->]0.050\n",
      "[epoch 17] train_loss: 0.129 train_accuracy: 0.950 val_accuracy: 0.960  recall: 0.939  f1: 0.947\n",
      "train loss:100%[**************************************************->]0.190\n",
      "[epoch 18] train_loss: 0.125 train_accuracy: 0.952 val_accuracy: 0.963  recall: 0.942  f1: 0.949\n",
      "train loss:100%[**************************************************->]0.100\n",
      "[epoch 19] train_loss: 0.121 train_accuracy: 0.955 val_accuracy: 0.949  recall: 0.931  f1: 0.938\n",
      "train loss:100%[**************************************************->]0.003\n",
      "[epoch 20] train_loss: 0.117 train_accuracy: 0.956 val_accuracy: 0.960  recall: 0.940  f1: 0.947\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.categories = sorted(os.listdir(data_dir))\n",
    "        self.data = []\n",
    "        self.transform = transform\n",
    "        for category in self.categories:\n",
    "            category_dir = os.path.join(data_dir, category)\n",
    "            category_data = sorted(os.listdir(category_dir))\n",
    "            self.data.extend([(os.path.join(category_dir, file), self.categories.index(category)) for file in category_data])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_path, label = self.data[index]\n",
    "        data = np.load(file_path)\n",
    "        image = Image.fromarray(data.astype(np.uint8))\n",
    "        image = transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using {} device.\".format(device))\n",
    "\n",
    "transform = transforms.Compose([ transforms.Grayscale(num_output_channels = 1),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "train_dataset = CustomDataset(\"features/train_npy\",transform=transform)\n",
    "train_num = len(train_dataset)\n",
    "dev_list = train_dataset.categories\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size, shuffle=True,\n",
    "                                               num_workers=0)\n",
    "\n",
    "validate_dataset = CustomDataset(\"features/val_npy\",transform=transform)\n",
    "val_num = len(validate_dataset)\n",
    "validate_loader = torch.utils.data.DataLoader(validate_dataset,\n",
    "                                                  batch_size=batch_size, shuffle=False,\n",
    "                                                  num_workers=0)\n",
    "\n",
    "print(\"using {} images for training, {} images for validation.\".format(train_num, val_num))\n",
    "\n",
    "net = AlexNet(num_classes=27, init_weights=True)\n",
    "net.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "\n",
    "epochs = 20\n",
    "save_path = './AlexNet_parameters.pth'\n",
    "best_f1 = 0.0\n",
    "train_accurate_list = []\n",
    "val_accurate_list = []\n",
    "f1_list = []\n",
    "recall_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # train\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for step, data in enumerate(train_loader, start=0):\n",
    "        images, labels = data\n",
    "        images = images.reshape(images.shape[0], 1, 1500)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images.to(device))\n",
    "        predict_y = torch.max(outputs, dim=1)[1]\n",
    "        train_acc += torch.eq(predict_y, labels.to(device)).sum().item()\n",
    "        loss = loss_function(outputs,labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        rate = (step + 1) / len(train_loader)\n",
    "        a = \"*\" * int(rate * 50)\n",
    "        b = \".\" * int((1 - rate) * 50)\n",
    "        print(\"\\rtrain loss:{:^3.0f}%[{}->{}]{:.3f}\".format(int(rate * 100), a, b, loss), end=\"\")\n",
    "    print()\n",
    "    train_accurate = train_acc / train_num\n",
    "    train_accurate_list.append(train_accurate)\n",
    "    net.eval()\n",
    "    acc = 0.0 \n",
    "    val = torch.tensor([])\n",
    "    pre = torch.tensor([])\n",
    "    with torch.no_grad():\n",
    "        for val_data in validate_loader:\n",
    "            val_images, val_labels = val_data\n",
    "            val_images = val_images.reshape(val_images.shape[0], 1, 1500)\n",
    "            outputs = net(val_images.to(device))\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            pre = torch.cat([pre.to(device), predict_y.to(device)])\n",
    "            val = torch.cat([val.to(device), val_labels.to(device)])\n",
    "            acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "    val_accurate = acc / val_num\n",
    "    val_accurate_list.append(val_accurate)\n",
    "    f1 = f1_score(val.cpu(), pre.cpu(), average='macro')\n",
    "    recall = recall_score(val.cpu(), pre.cpu(), average='macro')\n",
    "\n",
    "    f1_list.append(f1)\n",
    "    recall_list.append(recall)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_pre = pre\n",
    "        best_val = val\n",
    "        torch.save(net.state_dict(), save_path)\n",
    "        torch.save(best_pre, 'pre_val_label/best_pre_AlexNet.pt')\n",
    "        torch.save(best_val, 'pre_val_label/best_val_AlexNet.pt')\n",
    "    print('[epoch %d] train_loss: %.3f train_accuracy: %.3f val_accuracy: %.3f  recall: %.3f  f1: %.3f' %\n",
    "              (epoch + 1, running_loss / step, train_accurate, val_accurate, recall, f1))\n",
    "    with open(\"AlexNet_result_npy.txt\", 'a') as file:\n",
    "        file.write(\"[epoch \" + str(epoch + 1) + \"]\" + \"  \" + \"train_accuracy:\" + str(train_accurate) + \"  \" + \"val_accuracy:\" + str(val_accurate) + \"  \" + \"recall:\" + str(recall) + \"  \" + \"f1:\" + str(f1) + '\\n')\n",
    "print('Finished Training')\n",
    "iterations = range(1, len(train_accurate_list) + 1)\n",
    "with open(\"AlexNet_npy_plt_data.txt\", 'a') as file:\n",
    "    file.write(\"iterations:\" + str(iterations) +\n",
    "               \"train_accurate_list:\" + str(train_accurate_list) +\n",
    "               \"val_accurate_list:\" + str(val_accurate_list) +\n",
    "               \"f1_list:\" + str(f1_list) +\n",
    "               \"recall_list:\" + str(recall_list) +\n",
    "               \"dev_list:\" + str(dev_list) + '\\n')\n",
    "conf_matrix = confusion_matrix(best_val.cpu(),best_pre.cpu())\n",
    "plot_matrix(conf_matrix,dev_list,\"AlexNet_confusion_matrix_npy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dac444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
