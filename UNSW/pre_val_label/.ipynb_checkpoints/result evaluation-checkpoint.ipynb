{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67f0299",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = ['Amazon Echo', 'Android Phone1', 'Android Phone2', 'Belkin Wemo switch', 'Belkin wemo motion sensor', 'Blipcare Blood Pressure meter', 'Dropcam', 'HP Printer', 'IPhone', 'Insteon Camera', 'Laptop', 'Light Bulbs LiFX Smart Bulb', 'MacBook', 'NEST Protect smoke alarm', 'Nest Dropcam', 'Netatmo Welcome', 'Netatmo weather station', 'PIX-STAR Photo-frame', 'Samsung Galaxy Tab', 'Samsung SmartCam', 'TP-Link Day Night Cloud camera', 'TP-Link Smart plug', 'Triby Speaker', 'Withings Aura smart sleep sensor', 'Withings Smart Baby Monitor', 'Withings Smart scale', 'iHome']\n",
    "dic = {'Amazon Echo': 0, 'Android Phone1': 1, 'Android Phone2': 2, 'Belkin Wemo switch': 3, 'Belkin wemo motion sensor': 4, 'Blipcare Blood Pressure meter': 5, 'Dropcam': 6, 'HP Printer': 7, 'IPhone': 8, 'Insteon Camera': 9, 'Laptop': 10, 'Light Bulbs LiFX Smart Bulb': 11, 'MacBook': 12, 'NEST Protect smoke alarm': 13, 'Nest Dropcam': 14, 'Netatmo Welcome': 15, 'Netatmo weather station': 16, 'PIX-STAR Photo-frame': 17, 'Samsung Galaxy Tab': 18, 'Samsung SmartCam': 19, 'TP-Link Day Night Cloud camera': 20, 'TP-Link Smart plug': 21, 'Triby Speaker': 22, 'Withings Aura smart sleep sensor': 23, 'Withings Smart Baby Monitor': 24, 'Withings Smart scale': 25, 'iHome': 26}\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "\n",
    "def evaluate_metrics(predicted_labels, true_labels):\n",
    "    label_metrics = defaultdict(dict)\n",
    "\n",
    "    for label in true_labels:\n",
    "        label_metrics[label]['actual_count'] = true_labels.count(label)\n",
    "    for label in predicted_labels:\n",
    "        label_metrics[label]['predicted_count'] = predicted_labels.count(label)\n",
    "\n",
    "    for label in set(true_labels):\n",
    "        true_positives = sum((p_label == label) and (t_label == label) for p_label, t_label in zip(predicted_labels, true_labels))\n",
    "        false_positives = sum((p_label == label) and (t_label != label) for p_label, t_label in zip(predicted_labels, true_labels))\n",
    "        false_negatives = sum((p_label != label) and (t_label == label) for p_label, t_label in zip(predicted_labels, true_labels))\n",
    "\n",
    "        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "        label_metrics[label]['precision'] = round(precision, 4)\n",
    "\n",
    "        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "        label_metrics[label]['recall'] = round(recall, 4)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        label_metrics[label]['f1_score'] = round(f1, 4)\n",
    "\n",
    "    return label_metrics\n",
    "\n",
    "predicted_labels = torch.load(\"best_pre_TrimSENet.pt\").tolist()\n",
    "true_labels = torch.load(\"best_val_TrimSENet.pt\").tolist()\n",
    "metrics = evaluate_metrics(predicted_labels, true_labels)\n",
    "\n",
    "for label, metric in metrics.items():\n",
    "    print(f\"Label: {label}\")\n",
    "    print(f\"Device: {[k for k, v in dic.items() if v == label]}\")\n",
    "    print(f\"Actual Count: {metric['actual_count']}\")\n",
    "    print(f\"Predicted Count: {metric['predicted_count']}\")\n",
    "    print(f\"Precision: {metric['precision']:.4f}\")\n",
    "    print(f\"Recall: {metric['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metric['f1_score']:.4f}\")\n",
    "    print()\n",
    "\n",
    "# import torch\n",
    "# from sklearn.metrics import precision_score\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.metrics import recall_score\n",
    "\n",
    "# arr = [(\"best_val_TrimSENet.pt\",\"best_pre_TrimSENet.pt\"),(\"best_val_AlexNet.pt\",\"best_pre_AlexNet.pt\"),\n",
    "#        (\"best_val_GoogLeNet.pt\",\"best_pre_GoogLeNet.pt\"),(\"best_val_MobileNet.pt\",\"best_pre_MobileNet.pt\"),\n",
    "#        (\"best_val_SENet.pt\",\"best_pre_SENet.pt\"),(\"best_val_VggNet.pt\",\"best_pre_VggNet.pt\")]\n",
    "\n",
    "# for i in arr:\n",
    "#     y_true_add, y_pred_add = i\n",
    "#     y_true = torch.load(y_true_add).tolist()\n",
    "#     y_pred = torch.load(y_pred_add).tolist()\n",
    "#     precision_macro = precision_score(y_true, y_pred, average='macro')\n",
    "#     recall = recall_score(y_true, y_pred, average='macro')\n",
    "#     accuracy = accuracy_score(y_true, y_pred)\n",
    "#     f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    \n",
    "#     print(y_true_add.split(\"_\")[2].split(\".\")[0])\n",
    "#     print(f\"Macro Precision: {precision_macro:.4f}\")\n",
    "#     print(f\"recall: {recall:.4f}\")\n",
    "#     print(f\"Accuracy: {accuracy:.4f}\")\n",
    "#     print(f\"f1: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
