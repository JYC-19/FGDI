{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ca507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, num_classes=40, init_weights=False):\n",
    "        super(VGG, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(23552, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da1d5528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_matrix(conf_matrix, dev_list, save_path):\n",
    "    plt.figure(figsize=(20, 16), dpi=300)\n",
    "    plt.imshow(conf_matrix, cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "\n",
    "    thresh = conf_matrix.max() / 2.\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            plt.text(j, i, conf_matrix[i, j],\n",
    "                     ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if conf_matrix[i, j] > thresh else \"black\", fontsize=6)\n",
    "\n",
    "    tick_marks = np.arange(len(dev_list))\n",
    "    plt.xticks(tick_marks, dev_list)\n",
    "    plt.yticks(tick_marks, dev_list)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e5f9c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0 device.\n",
      "using 86137 images for training, 21515 images for validation.\n",
      "train loss:100%[**************************************************->]0.752\n",
      "[epoch 1] train_loss: 1.340 train_accuracy: 0.546 val_accuracy: 0.685  recall: 0.521  f1: 0.532\n",
      "train loss:100%[**************************************************->]0.834\n",
      "[epoch 2] train_loss: 0.737 train_accuracy: 0.715 val_accuracy: 0.759  recall: 0.637  f1: 0.643\n",
      "train loss:100%[**************************************************->]1.099\n",
      "[epoch 3] train_loss: 0.568 train_accuracy: 0.777 val_accuracy: 0.805  recall: 0.716  f1: 0.739\n",
      "train loss:100%[**************************************************->]0.392\n",
      "[epoch 4] train_loss: 0.476 train_accuracy: 0.812 val_accuracy: 0.828  recall: 0.757  f1: 0.774\n",
      "train loss:100%[**************************************************->]0.624\n",
      "[epoch 5] train_loss: 0.408 train_accuracy: 0.839 val_accuracy: 0.846  recall: 0.779  f1: 0.802\n",
      "train loss:100%[**************************************************->]0.677\n",
      "[epoch 6] train_loss: 0.356 train_accuracy: 0.861 val_accuracy: 0.870  recall: 0.795  f1: 0.817\n",
      "train loss:100%[**************************************************->]0.234\n",
      "[epoch 7] train_loss: 0.311 train_accuracy: 0.880 val_accuracy: 0.874  recall: 0.802  f1: 0.823\n",
      "train loss:100%[**************************************************->]0.331\n",
      "[epoch 8] train_loss: 0.268 train_accuracy: 0.897 val_accuracy: 0.899  recall: 0.813  f1: 0.844\n",
      "train loss:100%[**************************************************->]0.205\n",
      "[epoch 9] train_loss: 0.235 train_accuracy: 0.911 val_accuracy: 0.905  recall: 0.840  f1: 0.855\n",
      "train loss:100%[**************************************************->]0.139\n",
      "[epoch 10] train_loss: 0.210 train_accuracy: 0.921 val_accuracy: 0.915  recall: 0.833  f1: 0.854\n",
      "train loss:100%[**************************************************->]0.063\n",
      "[epoch 11] train_loss: 0.192 train_accuracy: 0.928 val_accuracy: 0.919  recall: 0.856  f1: 0.873\n",
      "train loss:100%[**************************************************->]0.053\n",
      "[epoch 12] train_loss: 0.176 train_accuracy: 0.935 val_accuracy: 0.919  recall: 0.830  f1: 0.847\n",
      "train loss:100%[**************************************************->]0.067\n",
      "[epoch 13] train_loss: 0.160 train_accuracy: 0.941 val_accuracy: 0.923  recall: 0.834  f1: 0.848\n",
      "train loss:100%[**************************************************->]0.027\n",
      "[epoch 14] train_loss: 0.149 train_accuracy: 0.945 val_accuracy: 0.937  recall: 0.861  f1: 0.868\n",
      "train loss:100%[**************************************************->]0.175\n",
      "[epoch 15] train_loss: 0.141 train_accuracy: 0.949 val_accuracy: 0.932  recall: 0.862  f1: 0.864\n",
      "train loss:100%[**************************************************->]0.083\n",
      "[epoch 16] train_loss: 0.130 train_accuracy: 0.953 val_accuracy: 0.934  recall: 0.869  f1: 0.889\n",
      "train loss:100%[**************************************************->]0.001\n",
      "[epoch 17] train_loss: 0.124 train_accuracy: 0.955 val_accuracy: 0.945  recall: 0.882  f1: 0.888\n",
      "train loss:100%[**************************************************->]0.124\n",
      "[epoch 18] train_loss: 0.117 train_accuracy: 0.958 val_accuracy: 0.938  recall: 0.872  f1: 0.879\n",
      "train loss:100%[**************************************************->]1.017\n",
      "[epoch 19] train_loss: 0.108 train_accuracy: 0.960 val_accuracy: 0.942  recall: 0.880  f1: 0.883\n",
      "train loss:100%[**************************************************->]0.096\n",
      "[epoch 20] train_loss: 0.105 train_accuracy: 0.962 val_accuracy: 0.948  recall: 0.885  f1: 0.889\n",
      "train loss:100%[**************************************************->]0.123\n",
      "[epoch 21] train_loss: 0.099 train_accuracy: 0.963 val_accuracy: 0.942  recall: 0.885  f1: 0.888\n",
      "train loss:100%[**************************************************->]0.402\n",
      "[epoch 22] train_loss: 0.094 train_accuracy: 0.966 val_accuracy: 0.951  recall: 0.892  f1: 0.895\n",
      "train loss:100%[**************************************************->]0.027\n",
      "[epoch 23] train_loss: 0.093 train_accuracy: 0.966 val_accuracy: 0.940  recall: 0.880  f1: 0.878\n",
      "train loss:100%[**************************************************->]0.170\n",
      "[epoch 24] train_loss: 0.084 train_accuracy: 0.969 val_accuracy: 0.948  recall: 0.894  f1: 0.889\n",
      "train loss:100%[**************************************************->]0.040\n",
      "[epoch 25] train_loss: 0.083 train_accuracy: 0.970 val_accuracy: 0.946  recall: 0.888  f1: 0.885\n",
      "train loss:100%[**************************************************->]0.250\n",
      "[epoch 26] train_loss: 0.078 train_accuracy: 0.972 val_accuracy: 0.946  recall: 0.880  f1: 0.876\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 27] train_loss: 0.078 train_accuracy: 0.972 val_accuracy: 0.949  recall: 0.888  f1: 0.881\n",
      "train loss:100%[**************************************************->]0.017\n",
      "[epoch 28] train_loss: 0.073 train_accuracy: 0.973 val_accuracy: 0.951  recall: 0.892  f1: 0.893\n",
      "train loss:100%[**************************************************->]0.085\n",
      "[epoch 29] train_loss: 0.070 train_accuracy: 0.974 val_accuracy: 0.950  recall: 0.883  f1: 0.884\n",
      "train loss:100%[**************************************************->]0.033\n",
      "[epoch 30] train_loss: 0.068 train_accuracy: 0.976 val_accuracy: 0.949  recall: 0.890  f1: 0.894\n",
      "train loss:100%[**************************************************->]0.191\n",
      "[epoch 31] train_loss: 0.064 train_accuracy: 0.977 val_accuracy: 0.948  recall: 0.894  f1: 0.887\n",
      "train loss:100%[**************************************************->]0.154\n",
      "[epoch 32] train_loss: 0.064 train_accuracy: 0.977 val_accuracy: 0.955  recall: 0.897  f1: 0.898\n",
      "train loss:100%[**************************************************->]0.228\n",
      "[epoch 33] train_loss: 0.062 train_accuracy: 0.978 val_accuracy: 0.953  recall: 0.888  f1: 0.885\n",
      "train loss:100%[**************************************************->]0.062\n",
      "[epoch 34] train_loss: 0.058 train_accuracy: 0.979 val_accuracy: 0.957  recall: 0.903  f1: 0.904\n",
      "train loss:100%[**************************************************->]0.302\n",
      "[epoch 35] train_loss: 0.059 train_accuracy: 0.978 val_accuracy: 0.945  recall: 0.894  f1: 0.884\n",
      "train loss:100%[**************************************************->]0.012\n",
      "[epoch 36] train_loss: 0.057 train_accuracy: 0.979 val_accuracy: 0.956  recall: 0.899  f1: 0.894\n",
      "train loss:100%[**************************************************->]0.059\n",
      "[epoch 37] train_loss: 0.054 train_accuracy: 0.980 val_accuracy: 0.956  recall: 0.910  f1: 0.902\n",
      "train loss:100%[**************************************************->]0.003\n",
      "[epoch 38] train_loss: 0.053 train_accuracy: 0.981 val_accuracy: 0.956  recall: 0.908  f1: 0.902\n",
      "train loss:100%[**************************************************->]0.232\n",
      "[epoch 39] train_loss: 0.052 train_accuracy: 0.981 val_accuracy: 0.957  recall: 0.896  f1: 0.894\n",
      "train loss:100%[**************************************************->]0.057\n",
      "[epoch 40] train_loss: 0.051 train_accuracy: 0.981 val_accuracy: 0.954  recall: 0.898  f1: 0.894\n",
      "train loss:100%[**************************************************->]0.092\n",
      "[epoch 41] train_loss: 0.050 train_accuracy: 0.982 val_accuracy: 0.957  recall: 0.894  f1: 0.894\n",
      "train loss:100%[**************************************************->]0.006\n",
      "[epoch 42] train_loss: 0.049 train_accuracy: 0.982 val_accuracy: 0.960  recall: 0.912  f1: 0.912\n",
      "train loss:100%[**************************************************->]0.003\n",
      "[epoch 43] train_loss: 0.051 train_accuracy: 0.981 val_accuracy: 0.947  recall: 0.899  f1: 0.892\n",
      "train loss:100%[**************************************************->]0.013\n",
      "[epoch 44] train_loss: 0.047 train_accuracy: 0.983 val_accuracy: 0.961  recall: 0.910  f1: 0.905\n",
      "train loss:100%[**************************************************->]0.065\n",
      "[epoch 45] train_loss: 0.049 train_accuracy: 0.982 val_accuracy: 0.951  recall: 0.900  f1: 0.898\n",
      "train loss:100%[**************************************************->]0.466\n",
      "[epoch 46] train_loss: 0.047 train_accuracy: 0.984 val_accuracy: 0.950  recall: 0.884  f1: 0.877\n",
      "train loss:100%[**************************************************->]0.012\n",
      "[epoch 47] train_loss: 0.047 train_accuracy: 0.983 val_accuracy: 0.958  recall: 0.909  f1: 0.899\n",
      "train loss:100%[**************************************************->]0.115\n",
      "[epoch 48] train_loss: 0.046 train_accuracy: 0.984 val_accuracy: 0.958  recall: 0.909  f1: 0.907\n",
      "train loss:100%[**************************************************->]0.053\n",
      "[epoch 49] train_loss: 0.045 train_accuracy: 0.984 val_accuracy: 0.960  recall: 0.903  f1: 0.899\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 50] train_loss: 0.044 train_accuracy: 0.984 val_accuracy: 0.954  recall: 0.897  f1: 0.893\n",
      "train loss:100%[**************************************************->]0.230\n",
      "[epoch 51] train_loss: 0.043 train_accuracy: 0.985 val_accuracy: 0.956  recall: 0.913  f1: 0.903\n",
      "train loss:100%[**************************************************->]0.182\n",
      "[epoch 52] train_loss: 0.045 train_accuracy: 0.984 val_accuracy: 0.960  recall: 0.909  f1: 0.908\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 53] train_loss: 0.043 train_accuracy: 0.984 val_accuracy: 0.962  recall: 0.914  f1: 0.915\n",
      "train loss:100%[**************************************************->]0.071\n",
      "[epoch 54] train_loss: 0.041 train_accuracy: 0.985 val_accuracy: 0.960  recall: 0.903  f1: 0.900\n",
      "train loss:100%[**************************************************->]0.098\n",
      "[epoch 55] train_loss: 0.044 train_accuracy: 0.984 val_accuracy: 0.961  recall: 0.907  f1: 0.902\n",
      "train loss:100%[**************************************************->]0.067\n",
      "[epoch 56] train_loss: 0.042 train_accuracy: 0.985 val_accuracy: 0.962  recall: 0.907  f1: 0.907\n",
      "train loss:100%[**************************************************->]0.004\n",
      "[epoch 57] train_loss: 0.043 train_accuracy: 0.985 val_accuracy: 0.961  recall: 0.908  f1: 0.899\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 58] train_loss: 0.043 train_accuracy: 0.985 val_accuracy: 0.959  recall: 0.910  f1: 0.905\n",
      "train loss:100%[**************************************************->]0.007\n",
      "[epoch 59] train_loss: 0.040 train_accuracy: 0.986 val_accuracy: 0.959  recall: 0.908  f1: 0.904\n",
      "train loss:100%[**************************************************->]0.001\n",
      "[epoch 60] train_loss: 0.043 train_accuracy: 0.985 val_accuracy: 0.963  recall: 0.903  f1: 0.900\n",
      "train loss:100%[**************************************************->]0.008\n",
      "[epoch 61] train_loss: 0.042 train_accuracy: 0.986 val_accuracy: 0.962  recall: 0.913  f1: 0.911\n",
      "train loss:100%[**************************************************->]0.005\n",
      "[epoch 62] train_loss: 0.040 train_accuracy: 0.985 val_accuracy: 0.960  recall: 0.903  f1: 0.904\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 63] train_loss: 0.041 train_accuracy: 0.985 val_accuracy: 0.962  recall: 0.912  f1: 0.916\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 64] train_loss: 0.040 train_accuracy: 0.986 val_accuracy: 0.963  recall: 0.915  f1: 0.909\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 65] train_loss: 0.040 train_accuracy: 0.986 val_accuracy: 0.964  recall: 0.919  f1: 0.918\n",
      "train loss:100%[**************************************************->]0.002\n",
      "[epoch 66] train_loss: 0.037 train_accuracy: 0.986 val_accuracy: 0.960  recall: 0.914  f1: 0.903\n",
      "train loss:100%[**************************************************->]0.011\n",
      "[epoch 67] train_loss: 0.042 train_accuracy: 0.986 val_accuracy: 0.962  recall: 0.912  f1: 0.910\n",
      "train loss:100%[**************************************************->]0.005\n",
      "[epoch 68] train_loss: 0.040 train_accuracy: 0.986 val_accuracy: 0.964  recall: 0.914  f1: 0.910\n",
      "train loss:100%[**************************************************->]0.012\n",
      "[epoch 69] train_loss: 0.039 train_accuracy: 0.986 val_accuracy: 0.957  recall: 0.896  f1: 0.887\n",
      "train loss:100%[**************************************************->]0.006\n",
      "[epoch 70] train_loss: 0.040 train_accuracy: 0.986 val_accuracy: 0.962  recall: 0.917  f1: 0.917\n",
      "train loss:100%[**************************************************->]0.003\n",
      "[epoch 71] train_loss: 0.038 train_accuracy: 0.986 val_accuracy: 0.964  recall: 0.920  f1: 0.915\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 72] train_loss: 0.038 train_accuracy: 0.987 val_accuracy: 0.962  recall: 0.920  f1: 0.914\n",
      "train loss:100%[**************************************************->]0.024\n",
      "[epoch 73] train_loss: 0.038 train_accuracy: 0.987 val_accuracy: 0.961  recall: 0.917  f1: 0.915\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 74] train_loss: 0.039 train_accuracy: 0.986 val_accuracy: 0.961  recall: 0.910  f1: 0.904\n",
      "train loss:100%[**************************************************->]0.001\n",
      "[epoch 75] train_loss: 0.038 train_accuracy: 0.987 val_accuracy: 0.962  recall: 0.906  f1: 0.907\n",
      "train loss:100%[**************************************************->]0.022\n",
      "[epoch 76] train_loss: 0.039 train_accuracy: 0.987 val_accuracy: 0.962  recall: 0.911  f1: 0.913\n",
      "train loss:100%[**************************************************->]0.042\n",
      "[epoch 77] train_loss: 0.036 train_accuracy: 0.987 val_accuracy: 0.965  recall: 0.908  f1: 0.911\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 78] train_loss: 0.038 train_accuracy: 0.987 val_accuracy: 0.960  recall: 0.909  f1: 0.906\n",
      "train loss:100%[**************************************************->]0.072\n",
      "[epoch 79] train_loss: 0.040 train_accuracy: 0.987 val_accuracy: 0.964  recall: 0.918  f1: 0.912\n",
      "train loss:100%[**************************************************->]0.057\n",
      "[epoch 80] train_loss: 0.045 train_accuracy: 0.987 val_accuracy: 0.958  recall: 0.892  f1: 0.890\n",
      "train loss:100%[**************************************************->]0.009\n",
      "[epoch 81] train_loss: 0.035 train_accuracy: 0.988 val_accuracy: 0.967  recall: 0.921  f1: 0.914\n",
      "train loss:100%[**************************************************->]0.033\n",
      "[epoch 82] train_loss: 0.036 train_accuracy: 0.988 val_accuracy: 0.961  recall: 0.912  f1: 0.913\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 83] train_loss: 0.039 train_accuracy: 0.986 val_accuracy: 0.966  recall: 0.913  f1: 0.912\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 84] train_loss: 0.038 train_accuracy: 0.987 val_accuracy: 0.963  recall: 0.917  f1: 0.913\n",
      "train loss:100%[**************************************************->]0.021\n",
      "[epoch 85] train_loss: 0.036 train_accuracy: 0.987 val_accuracy: 0.964  recall: 0.919  f1: 0.907\n",
      "train loss:100%[**************************************************->]0.012\n",
      "[epoch 86] train_loss: 0.039 train_accuracy: 0.987 val_accuracy: 0.963  recall: 0.917  f1: 0.909\n",
      "train loss:100%[**************************************************->]0.002\n",
      "[epoch 87] train_loss: 0.037 train_accuracy: 0.988 val_accuracy: 0.959  recall: 0.908  f1: 0.900\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 88] train_loss: 0.036 train_accuracy: 0.988 val_accuracy: 0.964  recall: 0.915  f1: 0.913\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 89] train_loss: 0.037 train_accuracy: 0.988 val_accuracy: 0.967  recall: 0.924  f1: 0.920\n",
      "train loss:100%[**************************************************->]0.007\n",
      "[epoch 90] train_loss: 0.038 train_accuracy: 0.987 val_accuracy: 0.967  recall: 0.923  f1: 0.924\n",
      "train loss:100%[**************************************************->]0.025\n",
      "[epoch 91] train_loss: 0.035 train_accuracy: 0.988 val_accuracy: 0.963  recall: 0.903  f1: 0.901\n",
      "train loss:100%[**************************************************->]0.028\n",
      "[epoch 92] train_loss: 0.035 train_accuracy: 0.988 val_accuracy: 0.962  recall: 0.913  f1: 0.911\n",
      "train loss:100%[**************************************************->]0.001\n",
      "[epoch 93] train_loss: 0.039 train_accuracy: 0.987 val_accuracy: 0.964  recall: 0.919  f1: 0.914\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 94] train_loss: 0.036 train_accuracy: 0.988 val_accuracy: 0.965  recall: 0.916  f1: 0.908\n",
      "train loss:100%[**************************************************->]0.001\n",
      "[epoch 95] train_loss: 0.035 train_accuracy: 0.988 val_accuracy: 0.966  recall: 0.915  f1: 0.910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 96] train_loss: 0.035 train_accuracy: 0.988 val_accuracy: 0.964  recall: 0.913  f1: 0.911\n",
      "train loss:100%[**************************************************->]0.068\n",
      "[epoch 97] train_loss: 0.034 train_accuracy: 0.988 val_accuracy: 0.965  recall: 0.915  f1: 0.907\n",
      "train loss:100%[**************************************************->]0.014\n",
      "[epoch 98] train_loss: 0.035 train_accuracy: 0.988 val_accuracy: 0.964  recall: 0.912  f1: 0.915\n",
      "train loss:100%[**************************************************->]0.009\n",
      "[epoch 99] train_loss: 0.036 train_accuracy: 0.988 val_accuracy: 0.964  recall: 0.906  f1: 0.904\n",
      "train loss:100%[**************************************************->]0.049\n",
      "[epoch 100] train_loss: 0.042 train_accuracy: 0.988 val_accuracy: 0.965  recall: 0.914  f1: 0.911\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.categories = sorted(os.listdir(data_dir))\n",
    "        self.data = []\n",
    "        self.transform = transform\n",
    "        for category in self.categories:\n",
    "            category_dir = os.path.join(data_dir, category)\n",
    "            category_data = sorted(os.listdir(category_dir))\n",
    "            self.data.extend([(os.path.join(category_dir, file), self.categories.index(category)) for file in category_data])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_path, label = self.data[index]\n",
    "        data = np.load(file_path)\n",
    "        image = Image.fromarray(data.astype(np.uint8))\n",
    "        image = transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using {} device.\".format(device))\n",
    "\n",
    "transform = transforms.Compose([ transforms.Grayscale(num_output_channels = 1),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "train_dataset = CustomDataset(\"features/train_npy\",transform=transform)\n",
    "train_num = len(train_dataset)\n",
    "dev_list = train_dataset.categories\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size, shuffle=True,\n",
    "                                               num_workers=0)\n",
    "\n",
    "validate_dataset = CustomDataset(\"features/val_npy\",transform=transform)\n",
    "val_num = len(validate_dataset)\n",
    "validate_loader = torch.utils.data.DataLoader(validate_dataset,\n",
    "                                                  batch_size=batch_size, shuffle=False,\n",
    "                                                  num_workers=0)\n",
    "\n",
    "print(\"using {} images for training, {} images for validation.\".format(train_num, val_num))\n",
    "\n",
    "net = VGG(num_classes=31,init_weights=True)\n",
    "net.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "\n",
    "epochs = 100\n",
    "save_path = './VggNet_parameters.pth'\n",
    "best_f1 = 0.0\n",
    "train_accurate_list = []\n",
    "val_accurate_list = []\n",
    "f1_list = []\n",
    "recall_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for step, data in enumerate(train_loader, start=0):\n",
    "        images, labels = data\n",
    "        images = images.reshape(images.shape[0], 1, 1500)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images.to(device))\n",
    "        predict_y = torch.max(outputs, dim=1)[1]\n",
    "        train_acc += torch.eq(predict_y, labels.to(device)).sum().item()\n",
    "        loss = loss_function(outputs,labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        rate = (step + 1) / len(train_loader)\n",
    "        a = \"*\" * int(rate * 50)\n",
    "        b = \".\" * int((1 - rate) * 50)\n",
    "        print(\"\\rtrain loss:{:^3.0f}%[{}->{}]{:.3f}\".format(int(rate * 100), a, b, loss), end=\"\")\n",
    "    print()\n",
    "    train_accurate = train_acc / train_num\n",
    "    train_accurate_list.append(train_accurate)\n",
    "    net.eval()\n",
    "    acc = 0.0 \n",
    "    val = torch.tensor([])\n",
    "    pre = torch.tensor([])\n",
    "    with torch.no_grad():\n",
    "        for val_data in validate_loader:\n",
    "            val_images, val_labels = val_data\n",
    "            val_images = val_images.reshape(val_images.shape[0], 1, 1500)\n",
    "            outputs = net(val_images.to(device))\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            pre = torch.cat([pre.to(device), predict_y.to(device)])\n",
    "            val = torch.cat([val.to(device), val_labels.to(device)])\n",
    "            acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "    val_accurate = acc / val_num\n",
    "    val_accurate_list.append(val_accurate)\n",
    "    f1 = f1_score(val.cpu(), pre.cpu(), average='macro')\n",
    "    recall = recall_score(val.cpu(), pre.cpu(), average='macro')\n",
    "\n",
    "    f1_list.append(f1)\n",
    "    recall_list.append(recall)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_pre = pre\n",
    "        best_val = val\n",
    "        torch.save(net.state_dict(), save_path)\n",
    "        torch.save(best_pre, 'pre_val_label/best_pre_VggNet.pt')\n",
    "        torch.save(best_val, 'pre_val_label/best_val_VggNet.pt')\n",
    "    print('[epoch %d] train_loss: %.3f train_accuracy: %.3f val_accuracy: %.3f  recall: %.3f  f1: %.3f' %\n",
    "              (epoch + 1, running_loss / step, train_accurate, val_accurate, recall, f1))\n",
    "    with open(\"VggNet_result_npy.txt\", 'a') as file:\n",
    "        file.write(\"[epoch \" + str(epoch + 1) + \"]\" + \"  \" + \"train_accuracy:\" + str(train_accurate) + \"  \" + \"val_accuracy:\" + str(val_accurate) + \"  \" + \"recall:\" + str(recall) + \"  \" + \"f1:\" + str(f1) + '\\n')\n",
    "print('Finished Training')\n",
    "iterations = range(1, len(train_accurate_list) + 1)\n",
    "with open(\"VggNet_npy_plt_data.txt\", 'a') as file:\n",
    "    file.write(\"iterations:\" + str(iterations) +\n",
    "               \"train_accurate_list:\" + str(train_accurate_list) +\n",
    "               \"val_accurate_list:\" + str(val_accurate_list) +\n",
    "               \"f1_list:\" + str(f1_list) +\n",
    "               \"recall_list:\" + str(recall_list) +\n",
    "               \"dev_list:\" + str(dev_list) + '\\n')\n",
    "conf_matrix = confusion_matrix(best_val.cpu(),best_pre.cpu())\n",
    "plot_matrix(conf_matrix,dev_list,\"VggNet_confusion_matrix_npy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d930591a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
