{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8957f199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=40, init_weights=False):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(1, 48, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2),\n",
    "            nn.Conv1d(48, 128, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2),\n",
    "            nn.Conv1d(128, 192, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(192, 192, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(192, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(5760, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2048, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be28d864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_matrix(conf_matrix, dev_list, save_path):\n",
    "    plt.figure(figsize=(20, 16), dpi=300)\n",
    "    plt.imshow(conf_matrix, cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "\n",
    "    thresh = conf_matrix.max() / 2.\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            plt.text(j, i, conf_matrix[i, j],\n",
    "                     ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if conf_matrix[i, j] > thresh else \"black\", fontsize=6)\n",
    "\n",
    "    tick_marks = np.arange(len(dev_list))\n",
    "    plt.xticks(tick_marks, dev_list)\n",
    "    plt.yticks(tick_marks, dev_list)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12283795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0 device.\n",
      "using 86137 images for training, 21515 images for validation.\n",
      "train loss:100%[**************************************************->]1.013\n",
      "[epoch 1] train_loss: 1.565 train_accuracy: 0.475 val_accuracy: 0.611  recall: 0.387  f1: 0.364\n",
      "train loss:100%[**************************************************->]0.784\n",
      "[epoch 2] train_loss: 0.982 train_accuracy: 0.627 val_accuracy: 0.655  recall: 0.495  f1: 0.485\n",
      "train loss:100%[**************************************************->]1.129\n",
      "[epoch 3] train_loss: 0.822 train_accuracy: 0.677 val_accuracy: 0.702  recall: 0.557  f1: 0.552\n",
      "train loss:100%[**************************************************->]0.624\n",
      "[epoch 4] train_loss: 0.733 train_accuracy: 0.709 val_accuracy: 0.719  recall: 0.589  f1: 0.586\n",
      "train loss:100%[**************************************************->]0.542\n",
      "[epoch 5] train_loss: 0.678 train_accuracy: 0.727 val_accuracy: 0.747  recall: 0.611  f1: 0.613\n",
      "train loss:100%[**************************************************->]0.872\n",
      "[epoch 6] train_loss: 0.637 train_accuracy: 0.744 val_accuracy: 0.753  recall: 0.640  f1: 0.641\n",
      "train loss:100%[**************************************************->]0.629\n",
      "[epoch 7] train_loss: 0.597 train_accuracy: 0.761 val_accuracy: 0.777  recall: 0.660  f1: 0.668\n",
      "train loss:100%[**************************************************->]0.321\n",
      "[epoch 8] train_loss: 0.563 train_accuracy: 0.774 val_accuracy: 0.793  recall: 0.678  f1: 0.701\n",
      "train loss:100%[**************************************************->]0.554\n",
      "[epoch 9] train_loss: 0.531 train_accuracy: 0.788 val_accuracy: 0.791  recall: 0.693  f1: 0.709\n",
      "train loss:100%[**************************************************->]0.256\n",
      "[epoch 10] train_loss: 0.502 train_accuracy: 0.800 val_accuracy: 0.815  recall: 0.696  f1: 0.722\n",
      "train loss:100%[**************************************************->]0.245\n",
      "[epoch 11] train_loss: 0.471 train_accuracy: 0.814 val_accuracy: 0.815  recall: 0.715  f1: 0.719\n",
      "train loss:100%[**************************************************->]0.255\n",
      "[epoch 12] train_loss: 0.451 train_accuracy: 0.822 val_accuracy: 0.825  recall: 0.720  f1: 0.740\n",
      "train loss:100%[**************************************************->]0.274\n",
      "[epoch 13] train_loss: 0.431 train_accuracy: 0.830 val_accuracy: 0.834  recall: 0.722  f1: 0.737\n",
      "train loss:100%[**************************************************->]0.413\n",
      "[epoch 14] train_loss: 0.412 train_accuracy: 0.838 val_accuracy: 0.837  recall: 0.743  f1: 0.748\n",
      "train loss:100%[**************************************************->]0.498\n",
      "[epoch 15] train_loss: 0.395 train_accuracy: 0.843 val_accuracy: 0.838  recall: 0.726  f1: 0.743\n",
      "train loss:100%[**************************************************->]0.213\n",
      "[epoch 16] train_loss: 0.380 train_accuracy: 0.851 val_accuracy: 0.841  recall: 0.737  f1: 0.749\n",
      "train loss:100%[**************************************************->]0.384\n",
      "[epoch 17] train_loss: 0.367 train_accuracy: 0.854 val_accuracy: 0.844  recall: 0.743  f1: 0.746\n",
      "train loss:100%[**************************************************->]0.357\n",
      "[epoch 18] train_loss: 0.353 train_accuracy: 0.862 val_accuracy: 0.852  recall: 0.772  f1: 0.790\n",
      "train loss:100%[**************************************************->]0.564\n",
      "[epoch 19] train_loss: 0.340 train_accuracy: 0.866 val_accuracy: 0.853  recall: 0.748  f1: 0.752\n",
      "train loss:100%[**************************************************->]0.267\n",
      "[epoch 20] train_loss: 0.329 train_accuracy: 0.870 val_accuracy: 0.855  recall: 0.758  f1: 0.761\n",
      "train loss:100%[**************************************************->]0.349\n",
      "[epoch 21] train_loss: 0.319 train_accuracy: 0.875 val_accuracy: 0.858  recall: 0.756  f1: 0.766\n",
      "train loss:100%[**************************************************->]0.606\n",
      "[epoch 22] train_loss: 0.309 train_accuracy: 0.879 val_accuracy: 0.862  recall: 0.785  f1: 0.803\n",
      "train loss:100%[**************************************************->]0.059\n",
      "[epoch 23] train_loss: 0.302 train_accuracy: 0.882 val_accuracy: 0.874  recall: 0.782  f1: 0.785\n",
      "train loss:100%[**************************************************->]0.620\n",
      "[epoch 24] train_loss: 0.289 train_accuracy: 0.887 val_accuracy: 0.865  recall: 0.789  f1: 0.802\n",
      "train loss:100%[**************************************************->]0.330\n",
      "[epoch 25] train_loss: 0.282 train_accuracy: 0.890 val_accuracy: 0.870  recall: 0.796  f1: 0.818\n",
      "train loss:100%[**************************************************->]0.326\n",
      "[epoch 26] train_loss: 0.275 train_accuracy: 0.893 val_accuracy: 0.865  recall: 0.784  f1: 0.804\n",
      "train loss:100%[**************************************************->]0.379\n",
      "[epoch 27] train_loss: 0.264 train_accuracy: 0.898 val_accuracy: 0.875  recall: 0.805  f1: 0.809\n",
      "train loss:100%[**************************************************->]0.145\n",
      "[epoch 28] train_loss: 0.257 train_accuracy: 0.902 val_accuracy: 0.875  recall: 0.793  f1: 0.814\n",
      "train loss:100%[**************************************************->]0.122\n",
      "[epoch 29] train_loss: 0.252 train_accuracy: 0.903 val_accuracy: 0.880  recall: 0.800  f1: 0.801\n",
      "train loss:100%[**************************************************->]0.217\n",
      "[epoch 30] train_loss: 0.242 train_accuracy: 0.906 val_accuracy: 0.884  recall: 0.807  f1: 0.823\n",
      "train loss:100%[**************************************************->]0.385\n",
      "[epoch 31] train_loss: 0.237 train_accuracy: 0.908 val_accuracy: 0.890  recall: 0.814  f1: 0.836\n",
      "train loss:100%[**************************************************->]0.128\n",
      "[epoch 32] train_loss: 0.231 train_accuracy: 0.912 val_accuracy: 0.889  recall: 0.815  f1: 0.829\n",
      "train loss:100%[**************************************************->]0.459\n",
      "[epoch 33] train_loss: 0.223 train_accuracy: 0.914 val_accuracy: 0.888  recall: 0.819  f1: 0.835\n",
      "train loss:100%[**************************************************->]0.101\n",
      "[epoch 34] train_loss: 0.219 train_accuracy: 0.916 val_accuracy: 0.893  recall: 0.809  f1: 0.830\n",
      "train loss:100%[**************************************************->]0.221\n",
      "[epoch 35] train_loss: 0.212 train_accuracy: 0.919 val_accuracy: 0.893  recall: 0.821  f1: 0.833\n",
      "train loss:100%[**************************************************->]0.063\n",
      "[epoch 36] train_loss: 0.207 train_accuracy: 0.920 val_accuracy: 0.892  recall: 0.817  f1: 0.833\n",
      "train loss:100%[**************************************************->]0.077\n",
      "[epoch 37] train_loss: 0.200 train_accuracy: 0.923 val_accuracy: 0.896  recall: 0.829  f1: 0.839\n",
      "train loss:100%[**************************************************->]0.164\n",
      "[epoch 38] train_loss: 0.196 train_accuracy: 0.925 val_accuracy: 0.899  recall: 0.829  f1: 0.841\n",
      "train loss:100%[**************************************************->]0.099\n",
      "[epoch 39] train_loss: 0.195 train_accuracy: 0.925 val_accuracy: 0.899  recall: 0.827  f1: 0.839\n",
      "train loss:100%[**************************************************->]0.191\n",
      "[epoch 40] train_loss: 0.189 train_accuracy: 0.928 val_accuracy: 0.902  recall: 0.830  f1: 0.839\n",
      "train loss:100%[**************************************************->]0.100\n",
      "[epoch 41] train_loss: 0.184 train_accuracy: 0.931 val_accuracy: 0.900  recall: 0.842  f1: 0.842\n",
      "train loss:100%[**************************************************->]0.260\n",
      "[epoch 42] train_loss: 0.181 train_accuracy: 0.931 val_accuracy: 0.902  recall: 0.838  f1: 0.848\n",
      "train loss:100%[**************************************************->]0.199\n",
      "[epoch 43] train_loss: 0.176 train_accuracy: 0.933 val_accuracy: 0.901  recall: 0.832  f1: 0.837\n",
      "train loss:100%[**************************************************->]0.045\n",
      "[epoch 44] train_loss: 0.172 train_accuracy: 0.935 val_accuracy: 0.901  recall: 0.835  f1: 0.845\n",
      "train loss:100%[**************************************************->]0.003\n",
      "[epoch 45] train_loss: 0.169 train_accuracy: 0.936 val_accuracy: 0.909  recall: 0.834  f1: 0.851\n",
      "train loss:100%[**************************************************->]0.009\n",
      "[epoch 46] train_loss: 0.165 train_accuracy: 0.937 val_accuracy: 0.905  recall: 0.834  f1: 0.844\n",
      "train loss:100%[**************************************************->]0.045\n",
      "[epoch 47] train_loss: 0.160 train_accuracy: 0.940 val_accuracy: 0.899  recall: 0.831  f1: 0.846\n",
      "train loss:100%[**************************************************->]0.098\n",
      "[epoch 48] train_loss: 0.155 train_accuracy: 0.940 val_accuracy: 0.906  recall: 0.828  f1: 0.840\n",
      "train loss:100%[**************************************************->]0.132\n",
      "[epoch 49] train_loss: 0.154 train_accuracy: 0.941 val_accuracy: 0.910  recall: 0.839  f1: 0.852\n",
      "train loss:100%[**************************************************->]0.197\n",
      "[epoch 50] train_loss: 0.154 train_accuracy: 0.942 val_accuracy: 0.909  recall: 0.833  f1: 0.845\n",
      "train loss:100%[**************************************************->]0.051\n",
      "[epoch 51] train_loss: 0.149 train_accuracy: 0.943 val_accuracy: 0.912  recall: 0.853  f1: 0.859\n",
      "train loss:100%[**************************************************->]0.105\n",
      "[epoch 52] train_loss: 0.147 train_accuracy: 0.944 val_accuracy: 0.912  recall: 0.843  f1: 0.847\n",
      "train loss:100%[**************************************************->]0.134\n",
      "[epoch 53] train_loss: 0.144 train_accuracy: 0.944 val_accuracy: 0.910  recall: 0.839  f1: 0.844\n",
      "train loss:100%[**************************************************->]0.345\n",
      "[epoch 54] train_loss: 0.141 train_accuracy: 0.945 val_accuracy: 0.917  recall: 0.845  f1: 0.857\n",
      "train loss:100%[**************************************************->]0.094\n",
      "[epoch 55] train_loss: 0.137 train_accuracy: 0.947 val_accuracy: 0.911  recall: 0.842  f1: 0.847\n",
      "train loss:100%[**************************************************->]0.249\n",
      "[epoch 56] train_loss: 0.138 train_accuracy: 0.947 val_accuracy: 0.916  recall: 0.848  f1: 0.856\n",
      "train loss:100%[**************************************************->]0.074\n",
      "[epoch 57] train_loss: 0.132 train_accuracy: 0.950 val_accuracy: 0.917  recall: 0.851  f1: 0.856\n",
      "train loss:100%[**************************************************->]0.155\n",
      "[epoch 58] train_loss: 0.133 train_accuracy: 0.950 val_accuracy: 0.915  recall: 0.856  f1: 0.861\n",
      "train loss:100%[**************************************************->]0.096\n",
      "[epoch 59] train_loss: 0.127 train_accuracy: 0.951 val_accuracy: 0.918  recall: 0.854  f1: 0.859\n",
      "train loss:100%[**************************************************->]0.102\n",
      "[epoch 60] train_loss: 0.125 train_accuracy: 0.952 val_accuracy: 0.914  recall: 0.844  f1: 0.858\n",
      "train loss:100%[**************************************************->]0.228\n",
      "[epoch 61] train_loss: 0.127 train_accuracy: 0.950 val_accuracy: 0.919  recall: 0.861  f1: 0.865\n",
      "train loss:100%[**************************************************->]0.219\n",
      "[epoch 62] train_loss: 0.124 train_accuracy: 0.953 val_accuracy: 0.915  recall: 0.851  f1: 0.855\n",
      "train loss:100%[**************************************************->]0.151\n",
      "[epoch 63] train_loss: 0.120 train_accuracy: 0.954 val_accuracy: 0.920  recall: 0.859  f1: 0.867\n",
      "train loss:100%[**************************************************->]0.162\n",
      "[epoch 64] train_loss: 0.121 train_accuracy: 0.954 val_accuracy: 0.916  recall: 0.855  f1: 0.860\n",
      "train loss:100%[**************************************************->]0.052\n",
      "[epoch 65] train_loss: 0.116 train_accuracy: 0.955 val_accuracy: 0.917  recall: 0.856  f1: 0.862\n",
      "train loss:100%[**************************************************->]0.027\n",
      "[epoch 66] train_loss: 0.117 train_accuracy: 0.956 val_accuracy: 0.921  recall: 0.854  f1: 0.861\n",
      "train loss:100%[**************************************************->]0.011\n",
      "[epoch 67] train_loss: 0.114 train_accuracy: 0.956 val_accuracy: 0.919  recall: 0.865  f1: 0.865\n",
      "train loss:100%[**************************************************->]0.082\n",
      "[epoch 68] train_loss: 0.111 train_accuracy: 0.957 val_accuracy: 0.918  recall: 0.857  f1: 0.862\n",
      "train loss:100%[**************************************************->]0.136\n",
      "[epoch 69] train_loss: 0.111 train_accuracy: 0.957 val_accuracy: 0.923  recall: 0.869  f1: 0.863\n",
      "train loss:100%[**************************************************->]0.075\n",
      "[epoch 70] train_loss: 0.111 train_accuracy: 0.957 val_accuracy: 0.919  recall: 0.855  f1: 0.861\n",
      "train loss:100%[**************************************************->]0.013\n",
      "[epoch 71] train_loss: 0.109 train_accuracy: 0.959 val_accuracy: 0.920  recall: 0.858  f1: 0.868\n",
      "train loss:100%[**************************************************->]0.139\n",
      "[epoch 72] train_loss: 0.107 train_accuracy: 0.959 val_accuracy: 0.922  recall: 0.860  f1: 0.863\n",
      "train loss:100%[**************************************************->]0.062\n",
      "[epoch 73] train_loss: 0.106 train_accuracy: 0.960 val_accuracy: 0.920  recall: 0.859  f1: 0.863\n",
      "train loss:100%[**************************************************->]0.076\n",
      "[epoch 74] train_loss: 0.105 train_accuracy: 0.960 val_accuracy: 0.923  recall: 0.870  f1: 0.872\n",
      "train loss:100%[**************************************************->]0.034\n",
      "[epoch 75] train_loss: 0.102 train_accuracy: 0.961 val_accuracy: 0.921  recall: 0.870  f1: 0.871\n",
      "train loss:100%[**************************************************->]0.230\n",
      "[epoch 76] train_loss: 0.102 train_accuracy: 0.961 val_accuracy: 0.923  recall: 0.865  f1: 0.871\n",
      "train loss:100%[**************************************************->]0.060\n",
      "[epoch 77] train_loss: 0.100 train_accuracy: 0.962 val_accuracy: 0.922  recall: 0.872  f1: 0.869\n",
      "train loss:100%[**************************************************->]0.166\n",
      "[epoch 78] train_loss: 0.101 train_accuracy: 0.961 val_accuracy: 0.923  recall: 0.859  f1: 0.867\n",
      "train loss:100%[**************************************************->]0.142\n",
      "[epoch 79] train_loss: 0.098 train_accuracy: 0.963 val_accuracy: 0.924  recall: 0.862  f1: 0.868\n",
      "train loss:100%[**************************************************->]0.068\n",
      "[epoch 80] train_loss: 0.099 train_accuracy: 0.962 val_accuracy: 0.922  recall: 0.852  f1: 0.855\n",
      "train loss:100%[**************************************************->]0.195\n",
      "[epoch 81] train_loss: 0.094 train_accuracy: 0.964 val_accuracy: 0.924  recall: 0.877  f1: 0.878\n",
      "train loss:100%[**************************************************->]0.026\n",
      "[epoch 82] train_loss: 0.095 train_accuracy: 0.963 val_accuracy: 0.929  recall: 0.880  f1: 0.884\n",
      "train loss:100%[**************************************************->]0.011\n",
      "[epoch 83] train_loss: 0.094 train_accuracy: 0.964 val_accuracy: 0.928  recall: 0.866  f1: 0.872\n",
      "train loss:100%[**************************************************->]0.010\n",
      "[epoch 84] train_loss: 0.091 train_accuracy: 0.965 val_accuracy: 0.920  recall: 0.853  f1: 0.849\n",
      "train loss:100%[**************************************************->]0.010\n",
      "[epoch 85] train_loss: 0.092 train_accuracy: 0.965 val_accuracy: 0.924  recall: 0.856  f1: 0.859\n",
      "train loss:100%[**************************************************->]0.013\n",
      "[epoch 86] train_loss: 0.091 train_accuracy: 0.965 val_accuracy: 0.928  recall: 0.872  f1: 0.869\n",
      "train loss:100%[**************************************************->]0.108\n",
      "[epoch 87] train_loss: 0.091 train_accuracy: 0.966 val_accuracy: 0.920  recall: 0.860  f1: 0.856\n",
      "train loss:100%[**************************************************->]0.041\n",
      "[epoch 88] train_loss: 0.091 train_accuracy: 0.966 val_accuracy: 0.927  recall: 0.865  f1: 0.870\n",
      "train loss:100%[**************************************************->]0.071\n",
      "[epoch 89] train_loss: 0.089 train_accuracy: 0.966 val_accuracy: 0.925  recall: 0.863  f1: 0.864\n",
      "train loss:100%[**************************************************->]0.065\n",
      "[epoch 90] train_loss: 0.087 train_accuracy: 0.967 val_accuracy: 0.925  recall: 0.874  f1: 0.877\n",
      "train loss:100%[**************************************************->]0.042\n",
      "[epoch 91] train_loss: 0.088 train_accuracy: 0.966 val_accuracy: 0.925  recall: 0.861  f1: 0.861\n",
      "train loss:100%[**************************************************->]0.034\n",
      "[epoch 92] train_loss: 0.085 train_accuracy: 0.967 val_accuracy: 0.928  recall: 0.868  f1: 0.867\n",
      "train loss:100%[**************************************************->]0.518\n",
      "[epoch 93] train_loss: 0.083 train_accuracy: 0.968 val_accuracy: 0.924  recall: 0.867  f1: 0.871\n",
      "train loss:100%[**************************************************->]0.127\n",
      "[epoch 94] train_loss: 0.084 train_accuracy: 0.968 val_accuracy: 0.923  recall: 0.868  f1: 0.864\n",
      "train loss:100%[**************************************************->]0.045\n",
      "[epoch 95] train_loss: 0.083 train_accuracy: 0.968 val_accuracy: 0.924  recall: 0.870  f1: 0.880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:100%[**************************************************->]0.080\n",
      "[epoch 96] train_loss: 0.084 train_accuracy: 0.968 val_accuracy: 0.926  recall: 0.869  f1: 0.867\n",
      "train loss:100%[**************************************************->]0.045\n",
      "[epoch 97] train_loss: 0.080 train_accuracy: 0.969 val_accuracy: 0.927  recall: 0.879  f1: 0.881\n",
      "train loss:100%[**************************************************->]0.027\n",
      "[epoch 98] train_loss: 0.081 train_accuracy: 0.969 val_accuracy: 0.929  recall: 0.874  f1: 0.871\n",
      "train loss:100%[**************************************************->]0.252\n",
      "[epoch 99] train_loss: 0.079 train_accuracy: 0.970 val_accuracy: 0.928  recall: 0.866  f1: 0.873\n",
      "train loss:100%[**************************************************->]0.002\n",
      "[epoch 100] train_loss: 0.081 train_accuracy: 0.970 val_accuracy: 0.933  recall: 0.878  f1: 0.889\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.categories = sorted(os.listdir(data_dir))\n",
    "        self.data = []\n",
    "        self.transform = transform\n",
    "        for category in self.categories:\n",
    "            category_dir = os.path.join(data_dir, category)\n",
    "            category_data = sorted(os.listdir(category_dir))\n",
    "            self.data.extend([(os.path.join(category_dir, file), self.categories.index(category)) for file in category_data])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_path, label = self.data[index]\n",
    "        data = np.load(file_path)\n",
    "        image = Image.fromarray(data.astype(np.uint8))\n",
    "        image = transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using {} device.\".format(device))\n",
    "\n",
    "transform = transforms.Compose([ transforms.Grayscale(num_output_channels = 1),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "train_dataset = CustomDataset(\"features/train_npy\",transform=transform)\n",
    "train_num = len(train_dataset)\n",
    "dev_list = train_dataset.categories\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size, shuffle=True,\n",
    "                                               num_workers=0)\n",
    "\n",
    "validate_dataset = CustomDataset(\"features/val_npy\",transform=transform)\n",
    "val_num = len(validate_dataset)\n",
    "validate_loader = torch.utils.data.DataLoader(validate_dataset,\n",
    "                                                  batch_size=batch_size, shuffle=False,\n",
    "                                                  num_workers=0)\n",
    "\n",
    "print(\"using {} images for training, {} images for validation.\".format(train_num, val_num))\n",
    "\n",
    "net = AlexNet(num_classes=31, init_weights=True)\n",
    "net.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "\n",
    "epochs = 100\n",
    "save_path = './AlexNet_parameters.pth'\n",
    "best_f1 = 0.0\n",
    "train_accurate_list = []\n",
    "val_accurate_list = []\n",
    "f1_list = []\n",
    "recall_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for step, data in enumerate(train_loader, start=0):\n",
    "        images, labels = data\n",
    "        images = images.reshape(images.shape[0], 1, 1500)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images.to(device))\n",
    "        predict_y = torch.max(outputs, dim=1)[1]\n",
    "        train_acc += torch.eq(predict_y, labels.to(device)).sum().item()\n",
    "        loss = loss_function(outputs,labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        rate = (step + 1) / len(train_loader)\n",
    "        a = \"*\" * int(rate * 50)\n",
    "        b = \".\" * int((1 - rate) * 50)\n",
    "        print(\"\\rtrain loss:{:^3.0f}%[{}->{}]{:.3f}\".format(int(rate * 100), a, b, loss), end=\"\")\n",
    "    print()\n",
    "    train_accurate = train_acc / train_num\n",
    "    train_accurate_list.append(train_accurate)\n",
    "    net.eval()\n",
    "    acc = 0.0 \n",
    "    val = torch.tensor([])\n",
    "    pre = torch.tensor([])\n",
    "    with torch.no_grad():\n",
    "        for val_data in validate_loader:\n",
    "            val_images, val_labels = val_data\n",
    "            val_images = val_images.reshape(val_images.shape[0], 1, 1500)\n",
    "            outputs = net(val_images.to(device))\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            pre = torch.cat([pre.to(device), predict_y.to(device)])\n",
    "            val = torch.cat([val.to(device), val_labels.to(device)])\n",
    "            acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "    val_accurate = acc / val_num\n",
    "    val_accurate_list.append(val_accurate)\n",
    "    f1 = f1_score(val.cpu(), pre.cpu(), average='macro')\n",
    "    recall = recall_score(val.cpu(), pre.cpu(), average='macro')\n",
    "    f1_list.append(f1)\n",
    "    recall_list.append(recall)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_pre = pre\n",
    "        best_val = val\n",
    "        torch.save(net.state_dict(), save_path)\n",
    "        torch.save(best_pre, 'pre_val_label/best_pre_AlexNet.pt')\n",
    "        torch.save(best_val, 'pre_val_label/best_val_AlexNet.pt')\n",
    "    print('[epoch %d] train_loss: %.3f train_accuracy: %.3f val_accuracy: %.3f  recall: %.3f  f1: %.3f' %\n",
    "              (epoch + 1, running_loss / step, train_accurate, val_accurate, recall, f1))\n",
    "    with open(\"AlexNet_result_npy.txt\", 'a') as file:\n",
    "        file.write(\"[epoch \" + str(epoch + 1) + \"]\" + \"  \" + \"train_accuracy:\" + str(train_accurate) + \"  \" + \"val_accuracy:\" + str(val_accurate) + \"  \" + \"recall:\" + str(recall) + \"  \" + \"f1:\" + str(f1) + '\\n')\n",
    "print('Finished Training')\n",
    "\n",
    "iterations = range(1, len(train_accurate_list) + 1)\n",
    "with open(\"AlexNet_npy_plt_data.txt\", 'a') as file:\n",
    "    file.write(\"iterations:\" + str(iterations) +\n",
    "               \"train_accurate_list:\" + str(train_accurate_list) +\n",
    "               \"val_accurate_list:\" + str(val_accurate_list) +\n",
    "               \"f1_list:\" + str(f1_list) +\n",
    "               \"recall_list:\" + str(recall_list) +\n",
    "               \"dev_list:\" + str(dev_list) + '\\n')\n",
    "conf_matrix = confusion_matrix(best_val.cpu(),best_pre.cpu())\n",
    "plot_matrix(conf_matrix,dev_list,\"AlexNet_confusion_matrix_npy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850041dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
