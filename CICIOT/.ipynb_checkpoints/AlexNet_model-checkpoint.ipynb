{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9454f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=40, init_weights=False):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(1, 48, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2),\n",
    "            nn.Conv1d(48, 128, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2),\n",
    "            nn.Conv1d(128, 192, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(192, 192, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(192, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(5760, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2048, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77faaf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_matrix(conf_matrix, dev_list, save_path):\n",
    "    plt.figure(figsize=(20, 16))\n",
    "    plt.imshow(conf_matrix, cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "\n",
    "    thresh = conf_matrix.max() / 2.\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            plt.text(j, i, conf_matrix[i, j],\n",
    "                     ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if conf_matrix[i, j] > thresh else \"black\", fontsize=6)\n",
    "\n",
    "    tick_marks = np.arange(len(dev_list))\n",
    "    plt.xticks(tick_marks, dev_list)\n",
    "    plt.yticks(tick_marks, dev_list)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c0deb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0 device.\n",
      "using 312067 images for training, 78016 images for validation.\n",
      "train loss:100%[**************************************************->]0.001\n",
      "[epoch 1] train_loss: 0.874 train_accuracy: 0.733 val_accuracy: 0.877  recall: 0.855  f1: 0.853\n",
      "train loss:100%[**************************************************->]0.002\n",
      "[epoch 2] train_loss: 0.345 train_accuracy: 0.888 val_accuracy: 0.918  recall: 0.895  f1: 0.896\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 3] train_loss: 0.256 train_accuracy: 0.915 val_accuracy: 0.929  recall: 0.914  f1: 0.918\n",
      "train loss:100%[**************************************************->]0.003\n",
      "[epoch 4] train_loss: 0.213 train_accuracy: 0.928 val_accuracy: 0.940  recall: 0.931  f1: 0.934\n",
      "train loss:100%[**************************************************->]0.276\n",
      "[epoch 5] train_loss: 0.184 train_accuracy: 0.937 val_accuracy: 0.945  recall: 0.944  f1: 0.944\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 6] train_loss: 0.164 train_accuracy: 0.943 val_accuracy: 0.950  recall: 0.945  f1: 0.947\n",
      "train loss:100%[**************************************************->]0.420\n",
      "[epoch 7] train_loss: 0.148 train_accuracy: 0.948 val_accuracy: 0.956  recall: 0.957  f1: 0.957\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 8] train_loss: 0.135 train_accuracy: 0.952 val_accuracy: 0.958  recall: 0.950  f1: 0.953\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 9] train_loss: 0.124 train_accuracy: 0.956 val_accuracy: 0.962  recall: 0.960  f1: 0.961\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 10] train_loss: 0.113 train_accuracy: 0.960 val_accuracy: 0.962  recall: 0.961  f1: 0.962\n",
      "train loss:100%[**************************************************->]0.279\n",
      "[epoch 11] train_loss: 0.105 train_accuracy: 0.962 val_accuracy: 0.966  recall: 0.964  f1: 0.965\n",
      "train loss:100%[**************************************************->]0.048\n",
      "[epoch 12] train_loss: 0.097 train_accuracy: 0.964 val_accuracy: 0.968  recall: 0.967  f1: 0.967\n",
      "train loss:100%[**************************************************->]0.009\n",
      "[epoch 13] train_loss: 0.091 train_accuracy: 0.967 val_accuracy: 0.970  recall: 0.969  f1: 0.970\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 14] train_loss: 0.085 train_accuracy: 0.969 val_accuracy: 0.972  recall: 0.971  f1: 0.972\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 15] train_loss: 0.079 train_accuracy: 0.971 val_accuracy: 0.972  recall: 0.971  f1: 0.972\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 16] train_loss: 0.075 train_accuracy: 0.973 val_accuracy: 0.974  recall: 0.973  f1: 0.974\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 17] train_loss: 0.070 train_accuracy: 0.974 val_accuracy: 0.974  recall: 0.975  f1: 0.975\n",
      "train loss:100%[**************************************************->]0.002\n",
      "[epoch 18] train_loss: 0.066 train_accuracy: 0.976 val_accuracy: 0.977  recall: 0.976  f1: 0.976\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 19] train_loss: 0.063 train_accuracy: 0.977 val_accuracy: 0.976  recall: 0.974  f1: 0.974\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 20] train_loss: 0.059 train_accuracy: 0.978 val_accuracy: 0.979  recall: 0.980  f1: 0.980\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.categories = sorted(os.listdir(data_dir))\n",
    "        self.data = []\n",
    "        self.transform = transform\n",
    "        for category in self.categories:\n",
    "            category_dir = os.path.join(data_dir, category)\n",
    "            category_data = sorted(os.listdir(category_dir))\n",
    "            self.data.extend([(os.path.join(category_dir, file), self.categories.index(category)) for file in category_data])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_path, label = self.data[index]\n",
    "        data = np.load(file_path)\n",
    "        image = Image.fromarray(data.astype(np.uint8))\n",
    "        image = transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using {} device.\".format(device))\n",
    "\n",
    "transform = transforms.Compose([ transforms.Grayscale(num_output_channels = 1),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "train_dataset = CustomDataset(\"features/train_npy\",transform=transform)\n",
    "train_num = len(train_dataset)\n",
    "dev_list = train_dataset.categories\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size, shuffle=True,\n",
    "                                               num_workers=0)\n",
    "\n",
    "validate_dataset = CustomDataset(\"features/val_npy\",transform=transform)\n",
    "val_num = len(validate_dataset)\n",
    "validate_loader = torch.utils.data.DataLoader(validate_dataset,\n",
    "                                                  batch_size=batch_size, shuffle=False,\n",
    "                                                  num_workers=0)\n",
    "\n",
    "print(\"using {} images for training, {} images for validation.\".format(train_num, val_num))\n",
    "\n",
    "net = AlexNet(num_classes=40, init_weights=True)\n",
    "net.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "\n",
    "epochs = 20\n",
    "save_path = './AlexNet_parameters.pth'\n",
    "best_f1 = 0.0\n",
    "train_accurate_list = []\n",
    "val_accurate_list = []\n",
    "f1_list = []\n",
    "recall_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for step, data in enumerate(train_loader, start=0):\n",
    "        images, labels = data\n",
    "        images = images.reshape(images.shape[0], 1, 1500)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images.to(device))\n",
    "        predict_y = torch.max(outputs, dim=1)[1]\n",
    "        train_acc += torch.eq(predict_y, labels.to(device)).sum().item()\n",
    "        loss = loss_function(outputs,labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        rate = (step + 1) / len(train_loader)\n",
    "        a = \"*\" * int(rate * 50)\n",
    "        b = \".\" * int((1 - rate) * 50)\n",
    "        print(\"\\rtrain loss:{:^3.0f}%[{}->{}]{:.3f}\".format(int(rate * 100), a, b, loss), end=\"\")\n",
    "    print()\n",
    "    train_accurate = train_acc / train_num\n",
    "    train_accurate_list.append(train_accurate)\n",
    "    net.eval()\n",
    "    acc = 0.0  \n",
    "    val = torch.tensor([])\n",
    "    pre = torch.tensor([])\n",
    "    with torch.no_grad():\n",
    "        for val_data in validate_loader:\n",
    "            val_images, val_labels = val_data\n",
    "            val_images = val_images.reshape(val_images.shape[0], 1, 1500)\n",
    "            outputs = net(val_images.to(device))\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            pre = torch.cat([pre.to(device), predict_y.to(device)])\n",
    "            val = torch.cat([val.to(device), val_labels.to(device)])\n",
    "            acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "    val_accurate = acc / val_num\n",
    "    val_accurate_list.append(val_accurate)\n",
    "    f1 = f1_score(val.cpu(), pre.cpu(), average='macro')\n",
    "    recall = recall_score(val.cpu(), pre.cpu(), average='macro')\n",
    "\n",
    "    f1_list.append(f1)\n",
    "    recall_list.append(recall)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_pre = pre\n",
    "        best_val = val\n",
    "        torch.save(net.state_dict(), save_path)\n",
    "        torch.save(best_pre, 'pre_val_label/best_pre_AlexNet.pt')\n",
    "        torch.save(best_val, 'pre_val_label/best_val_AlexNet.pt')\n",
    "    print('[epoch %d] train_loss: %.3f train_accuracy: %.3f val_accuracy: %.3f  recall: %.3f  f1: %.3f' %\n",
    "              (epoch + 1, running_loss / step, train_accurate, val_accurate, recall, f1))\n",
    "    with open(\"AlexNet_result_npy.txt\", 'a') as file:\n",
    "        file.write(\"[epoch \" + str(epoch + 1) + \"]\" + \"  \" + \"train_accuracy:\" + str(train_accurate) + \"  \" + \"val_accuracy:\" + str(val_accurate) + \"  \" + \"recall:\" + str(recall) + \"  \" + \"f1:\" + str(f1) + '\\n')\n",
    "print('Finished Training')\n",
    "iterations = range(1, len(train_accurate_list) + 1)\n",
    "with open(\"AlexNet_npy_plt_data.txt\", 'a') as file:\n",
    "    file.write(\"iterations:\" + str(iterations) +\n",
    "               \"train_accurate_list:\" + str(train_accurate_list) +\n",
    "               \"val_accurate_list:\" + str(val_accurate_list) +\n",
    "               \"f1_list:\" + str(f1_list) +\n",
    "               \"recall_list:\" + str(recall_list) +\n",
    "               \"dev_list:\" + str(dev_list) + '\\n')\n",
    "conf_matrix = confusion_matrix(best_val.cpu(),best_pre.cpu())\n",
    "plot_matrix(conf_matrix,dev_list,\"AlexNet_confusion_matrix_npy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d95264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
