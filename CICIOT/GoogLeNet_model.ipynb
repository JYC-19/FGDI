{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b950e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self, num_classes=40, aux_logits=True, init_weights=True):\n",
    "        super(GoogLeNet,self).__init__()\n",
    "        self.aux_logits = aux_logits\n",
    "\n",
    "        self.conv1 = BasicConv1d(1, 64, kernel_size=7, stride=2, padding=3)    \n",
    "        self.maxpool1 = nn.MaxPool1d(3, stride=2, ceil_mode=True)        \n",
    "\n",
    "        self.conv2 = BasicConv1d(64, 64, kernel_size=1)\n",
    "        self.conv3 = BasicConv1d(64, 192, kernel_size=3, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool1d(3, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.maxpool3 = nn.MaxPool1d(3, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "        self.maxpool4 = nn.MaxPool1d(3, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "        if self.aux_logits:\n",
    "            self.aux1 = InceptionAux(512, num_classes)\n",
    "            self.aux2 = InceptionAux(528, num_classes)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.inception4a(x)\n",
    "        if self.training and self.aux_logits:\n",
    "            aux1 = self.aux1(x)\n",
    "\n",
    "        x = self.inception4b(x)\n",
    "        x = self.inception4c(x)\n",
    "        x = self.inception4d(x)\n",
    "        if self.training and self.aux_logits:\n",
    "            aux2 = self.aux2(x)\n",
    "\n",
    "        x = self.inception4e(x)\n",
    "        x = self.maxpool4(x)\n",
    "        x = self.inception5a(x)\n",
    "        x = self.inception5b(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        if self.training and self.aux_logits: \n",
    "            return x, aux2, aux1\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):\n",
    "        super(Inception,self).__init__()\n",
    "\n",
    "        self.branch1 = BasicConv1d(in_channels, ch1x1, kernel_size=1)\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv1d(in_channels, ch3x3red, kernel_size=1),\n",
    "            BasicConv1d(ch3x3red, ch3x3, kernel_size=3, padding=1)        \n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            BasicConv1d(in_channels, ch5x5red, kernel_size=1),\n",
    "            BasicConv1d(ch5x5red, ch5x5, kernel_size=5, padding=2)     \n",
    "        )\n",
    "\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=3, stride=1, padding=1),              \n",
    "            BasicConv1d(in_channels, pool_proj, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        branch3 = self.branch3(x)\n",
    "        branch4 = self.branch4(x)\n",
    "\n",
    "        outputs = [branch1, branch2, branch3, branch4]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "class InceptionAux(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(InceptionAux,self).__init__()\n",
    "        self.averagePool = nn.AvgPool1d(kernel_size=5, stride=3)\n",
    "        self.conv = BasicConv1d(in_channels, 128, kernel_size=1)          \n",
    "\n",
    "        self.fc1 = nn.Linear(3840, 1024)\n",
    "        self.fc2 = nn.Linear(1024,num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.averagePool(x)\n",
    "        x = self.conv(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = F.dropout(x, 0.5, training=self.training)\n",
    "        x = F.relu(self.fc1(x), inplace=True)\n",
    "        x = F.dropout(x, 0.5, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class BasicConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConv1d, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, **kwargs)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61498fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_matrix(conf_matrix, dev_list, save_path):\n",
    "    plt.figure(figsize=(20, 16))\n",
    "    plt.imshow(conf_matrix, cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "\n",
    "    thresh = conf_matrix.max() / 2.\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            plt.text(j, i, conf_matrix[i, j],\n",
    "                     ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if conf_matrix[i, j] > thresh else \"black\", fontsize=6)\n",
    "\n",
    "    tick_marks = np.arange(len(dev_list))\n",
    "    plt.xticks(tick_marks, dev_list)\n",
    "    plt.yticks(tick_marks, dev_list)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98479014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0 device.\n",
      "using 312067 images for training, 78016 images for validation.\n",
      "train loss:100%[**************************************************->]0.004\n",
      "[epoch 1] train_loss: 2.051 train_accuracy: 0.640 val_accuracy: 0.846  recall: 0.825  f1: 0.819\n",
      "train loss:100%[**************************************************->]0.219\n",
      "[epoch 2] train_loss: 0.817 train_accuracy: 0.858 val_accuracy: 0.893  recall: 0.870  f1: 0.869\n",
      "train loss:100%[**************************************************->]3.991\n",
      "[epoch 3] train_loss: 0.616 train_accuracy: 0.894 val_accuracy: 0.843  recall: 0.822  f1: 0.827\n",
      "train loss:100%[**************************************************->]0.175\n",
      "[epoch 4] train_loss: 0.507 train_accuracy: 0.912 val_accuracy: 0.920  recall: 0.902  f1: 0.905\n",
      "train loss:100%[**************************************************->]0.143\n",
      "[epoch 5] train_loss: 0.430 train_accuracy: 0.925 val_accuracy: 0.923  recall: 0.901  f1: 0.904\n",
      "train loss:100%[**************************************************->]0.003\n",
      "[epoch 6] train_loss: 0.375 train_accuracy: 0.934 val_accuracy: 0.941  recall: 0.921  f1: 0.923\n",
      "train loss:100%[**************************************************->]0.126\n",
      "[epoch 7] train_loss: 0.332 train_accuracy: 0.941 val_accuracy: 0.948  recall: 0.943  f1: 0.946\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 8] train_loss: 0.298 train_accuracy: 0.947 val_accuracy: 0.948  recall: 0.932  f1: 0.936\n",
      "train loss:100%[**************************************************->]0.003\n",
      "[epoch 9] train_loss: 0.270 train_accuracy: 0.951 val_accuracy: 0.950  recall: 0.934  f1: 0.936\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 10] train_loss: 0.245 train_accuracy: 0.955 val_accuracy: 0.960  recall: 0.958  f1: 0.960\n",
      "train loss:100%[**************************************************->]0.017\n",
      "[epoch 11] train_loss: 0.225 train_accuracy: 0.959 val_accuracy: 0.961  recall: 0.956  f1: 0.957\n",
      "train loss:100%[**************************************************->]0.001\n",
      "[epoch 12] train_loss: 0.207 train_accuracy: 0.962 val_accuracy: 0.964  recall: 0.955  f1: 0.956\n",
      "train loss:100%[**************************************************->]0.603\n",
      "[epoch 13] train_loss: 0.193 train_accuracy: 0.964 val_accuracy: 0.959  recall: 0.952  f1: 0.955\n",
      "train loss:100%[**************************************************->]0.834\n",
      "[epoch 14] train_loss: 0.180 train_accuracy: 0.966 val_accuracy: 0.967  recall: 0.965  f1: 0.963\n",
      "train loss:100%[**************************************************->]0.003\n",
      "[epoch 15] train_loss: 0.167 train_accuracy: 0.969 val_accuracy: 0.966  recall: 0.962  f1: 0.961\n",
      "train loss:100%[**************************************************->]0.001\n",
      "[epoch 16] train_loss: 0.155 train_accuracy: 0.971 val_accuracy: 0.965  recall: 0.962  f1: 0.962\n",
      "train loss:100%[**************************************************->]0.780\n",
      "[epoch 17] train_loss: 0.144 train_accuracy: 0.973 val_accuracy: 0.969  recall: 0.966  f1: 0.967\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 18] train_loss: 0.134 train_accuracy: 0.975 val_accuracy: 0.972  recall: 0.966  f1: 0.968\n",
      "train loss:100%[**************************************************->]0.000\n",
      "[epoch 19] train_loss: 0.125 train_accuracy: 0.977 val_accuracy: 0.976  recall: 0.975  f1: 0.972\n",
      "train loss:100%[**************************************************->]0.001\n",
      "[epoch 20] train_loss: 0.116 train_accuracy: 0.979 val_accuracy: 0.973  recall: 0.970  f1: 0.970\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.categories = sorted(os.listdir(data_dir))\n",
    "        self.data = []\n",
    "        self.transform = transform\n",
    "        for category in self.categories:\n",
    "            category_dir = os.path.join(data_dir, category)\n",
    "            category_data = sorted(os.listdir(category_dir))\n",
    "            self.data.extend([(os.path.join(category_dir, file), self.categories.index(category)) for file in category_data])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_path, label = self.data[index]\n",
    "        data = np.load(file_path)\n",
    "        image = Image.fromarray(data.astype(np.uint8))\n",
    "        image = transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using {} device.\".format(device))\n",
    "\n",
    "transform = transforms.Compose([ transforms.Grayscale(num_output_channels = 1),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "train_dataset = CustomDataset(\"features/train_npy\",transform=transform)\n",
    "train_num = len(train_dataset)\n",
    "dev_list = train_dataset.categories\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size, shuffle=True,\n",
    "                                               num_workers=0)\n",
    "\n",
    "validate_dataset = CustomDataset(\"features/val_npy\",transform=transform)\n",
    "val_num = len(validate_dataset)\n",
    "validate_loader = torch.utils.data.DataLoader(validate_dataset,\n",
    "                                                  batch_size=batch_size, shuffle=False,\n",
    "                                                  num_workers=0)\n",
    "\n",
    "print(\"using {} images for training, {} images for validation.\".format(train_num, val_num))\n",
    "\n",
    "net = GoogLeNet(num_classes=40, aux_logits=True, init_weights=True)\n",
    "net.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "\n",
    "epochs = 20\n",
    "save_path = './GoogLeNet_parameters.pth'\n",
    "best_f1 = 0.0\n",
    "train_accurate_list = []\n",
    "val_accurate_list = []\n",
    "f1_list = []\n",
    "recall_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for step, data in enumerate(train_loader, start=0):\n",
    "        images, labels = data\n",
    "        images = images.reshape(images.shape[0], 1, 1500)\n",
    "        optimizer.zero_grad()\n",
    "        logits, aux_logits2, aux_logits1 = net(images.to(device))\n",
    "        predict_y = torch.max(logits, dim=1)[1]\n",
    "        train_acc += torch.eq(predict_y, labels.to(device)).sum().item()\n",
    "        loss0 = loss_function(logits, labels.to(device))\n",
    "        loss1 = loss_function(aux_logits1, labels.to(device))\n",
    "        loss2 = loss_function(aux_logits2, labels.to(device))\n",
    "        loss = loss0 + loss1 * 0.3 + loss2 * 0.3\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        rate = (step + 1) / len(train_loader)\n",
    "        a = \"*\" * int(rate * 50)\n",
    "        b = \".\" * int((1 - rate) * 50)\n",
    "        print(\"\\rtrain loss:{:^3.0f}%[{}->{}]{:.3f}\".format(int(rate * 100), a, b, loss), end=\"\")\n",
    "    print()\n",
    "    train_accurate = train_acc / train_num\n",
    "    train_accurate_list.append(train_accurate)\n",
    "    net.eval()\n",
    "    acc = 0.0 \n",
    "    val = torch.tensor([])\n",
    "    pre = torch.tensor([])\n",
    "    with torch.no_grad():\n",
    "        for val_data in validate_loader:\n",
    "            val_images, val_labels = val_data\n",
    "            val_images = val_images.reshape(val_images.shape[0], 1, 1500)\n",
    "            outputs = net(val_images.to(device))\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            pre = torch.cat([pre.to(device), predict_y.to(device)])\n",
    "            val = torch.cat([val.to(device), val_labels.to(device)])\n",
    "            acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "    val_accurate = acc / val_num\n",
    "    val_accurate_list.append(val_accurate)\n",
    "    f1 = f1_score(val.cpu(), pre.cpu(), average='macro')\n",
    "    recall = recall_score(val.cpu(), pre.cpu(), average='macro')\n",
    "\n",
    "    f1_list.append(f1)\n",
    "    recall_list.append(recall)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_pre = pre\n",
    "        best_val = val\n",
    "        torch.save(net.state_dict(), save_path)\n",
    "        torch.save(best_pre, 'pre_val_label/best_pre_GoogLeNet.pt')\n",
    "        torch.save(best_val, 'pre_val_label/best_val_GoogLeNet.pt')\n",
    "    print('[epoch %d] train_loss: %.3f train_accuracy: %.3f val_accuracy: %.3f  recall: %.3f  f1: %.3f' %\n",
    "              (epoch + 1, running_loss / step, train_accurate, val_accurate, recall, f1))\n",
    "    with open(\"GoogLeNet_result_npy.txt\", 'a') as file:\n",
    "        file.write(\"[epoch \" + str(epoch + 1) + \"]\" + \"  \" + \"train_accuracy:\" + str(train_accurate) + \"  \" + \"val_accuracy:\" + str(val_accurate) + \"  \" + \"recall:\" + str(recall) + \"  \" + \"f1:\" + str(f1) + '\\n')\n",
    "print('Finished Training')\n",
    "iterations = range(1, len(train_accurate_list) + 1)\n",
    "with open(\"GoogLeNet_npy_plt_data.txt\", 'a') as file:\n",
    "    file.write(\"iterations:\" + str(iterations) +\n",
    "               \"train_accurate_list:\" + str(train_accurate_list) +\n",
    "               \"val_accurate_list:\" + str(val_accurate_list) +\n",
    "               \"f1_list:\" + str(f1_list) +\n",
    "               \"recall_list:\" + str(recall_list) +\n",
    "               \"dev_list:\" + str(dev_list) + '\\n')\n",
    "conf_matrix = confusion_matrix(best_val.cpu(),best_pre.cpu())\n",
    "plot_matrix(conf_matrix,dev_list,\"GoogLeNet_confusion_matrix_npy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ad0f33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
